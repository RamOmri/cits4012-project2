{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb912ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import ftfy\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa03ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('./data/seek_australia.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d2b13",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07686710",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_delete = ['job_board','geo','url'] # get rid of unnecessary features\n",
    "df = df.drop(features_to_delete, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f9fd59",
   "metadata": {},
   "source": [
    "Job description is necessary for all the tasks in this assignment, so it makes sense to drop rows that are missing these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237fa708",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['job_description'].isna().sum())\n",
    "df.dropna(subset=['job_description'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e430cc0c",
   "metadata": {},
   "source": [
    "Tokenize each row and decode the text to remove all the non-latin characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df[ \"job_description\"].index:\n",
    "    df.loc[i, \"job_description\"] = gensim.utils.simple_preprocess(\n",
    "        ftfy.fix_text(unicodedata.normalize(\"NFKD\",df.loc[i,\"job_description\"])), deacc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e32dd4",
   "metadata": {},
   "source": [
    "Create_tfidf function creates a dataframe with each row representing a document with corresponding tfidf scores and the columns showing the full corpus vocabulary. Thus the tfidf score for each word in each document can be looked up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8024e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Allows passing tokens to the vectorizer\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "def create_tfidf_df(tokens):  \n",
    "    tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None) \n",
    "\n",
    "    tdf = tfidf.fit_transform(tokens)\n",
    "    bow = pd.DataFrame(tdf.toarray(), columns = tfidf.get_feature_names_out())\n",
    "\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ef486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_bow = create_tfidf_df(df['job_description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea528389",
   "metadata": {},
   "source": [
    "Top x tfidf accepts a list of tokenized documents and removes all words that do not have the top x tfidf scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a3c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_x_tfidf(descriptions, tfidf_df, x):\n",
    "    new_descriptions = []\n",
    "    for idx, desc in enumerate(descriptions):\n",
    "        words = set(desc)        \n",
    "        if len(words) < x: \n",
    "            new_descriptions.append(desc)\n",
    "            continue\n",
    "\n",
    "        # Create a dictionary of words and their tfidf values and then sort them in descending order\n",
    "        tfidf_words = {word: tfidf_df.iloc[idx][word] for word in words}\n",
    "        tfidf_words = {k: v for k, v in sorted(tfidf_words.items(), key=lambda item: -item[1])}\n",
    "\n",
    "        for word in desc:\n",
    "            if word not in list(tfidf_words.keys())[:x]: # Remove all words who are not in the top ten tfidf scores\n",
    "                desc = list(filter(lambda x: x != word, desc))\n",
    "        new_descriptions.append(desc)\n",
    "    return new_descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb192c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['short_description'] = top_x_tfidf(df['job_description'], tfidf_bow, 10)\n",
    "df['short_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e3048",
   "metadata": {},
   "source": [
    "Split the dataframe into training, testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb29901",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test_val = train_test_split(df, test_size=0.3)\n",
    "\n",
    "test, val = train_test_split(test_val, test_size = float(1/3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3504360",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8805ea",
   "metadata": {},
   "source": [
    "Derive target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_type_target'] = df['job_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6844c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['job_type_target'] != 'Full Time', 'job_type_target'] = 'Other'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f574dac",
   "metadata": {},
   "source": [
    "Analyse class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c60fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_type_target'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa01ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class 'Full Time' is twice as large as 'Other'. Verify based on literature if such a distribution is too\n",
    "# imbalanced for this learning task "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba58b9f",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4543322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3931f8ce93702ec92af21f632a7247673a82decd980a4ceb2171679cfa65979b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
