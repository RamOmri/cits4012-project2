{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DA5MVM3Icay"
   },
   "source": [
    "# generating descriptions using autoencoders\n",
    "\n",
    "22274048, 23191175"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CiL9SwSQ9SS"
   },
   "source": [
    "This notebook shows a method used to generete job description from a trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtZckG3XRXjt"
   },
   "source": [
    "## Set up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9gmfIgyeDZF"
   },
   "source": [
    "Import necessary modules and load the dataframe. The job description needs to be truncated due to the demanding calculations used to train the autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GGpO9B8Ica2"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1653905713276,
     "user": {
      "displayName": "Omri Ram",
      "userId": "07837710711281572278"
     },
     "user_tz": -120
    },
    "id": "Kif7Yql7Ica3",
    "outputId": "9b10d7cf-e9a7-4e3b-e660-bc806d528f56"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/.shortcut-targets-by-id/1SN-8It-Z6Sun4CATVH-ShCfzdUAuexhH/remote_proj'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "script_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "script_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k69nAszNRUW5"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 2083,
     "status": "ok",
     "timestamp": 1653905715966,
     "user": {
      "displayName": "Omri Ram",
      "userId": "07837710711281572278"
     },
     "user_tz": -120
    },
    "id": "cxlYhckYIca5",
    "outputId": "2d75e4ac-6a78-41df-c25c-0adaa6d23b37"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-77ad434a-57fa-4c52-ae55-6d39b3ca5a52\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_type_target</th>\n",
       "      <th>short_description</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25579</th>\n",
       "      <td>Mining, Resources &amp; Energy</td>\n",
       "      <td>[premium, mechanical, group, pmg, is, leading,...</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>premium pmg plant job premium job employees jo...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>Healthcare &amp; Medical</td>\n",
       "      <td>[medical, advisor, global, pharma, sydney, gro...</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>medical advisor pharma ground breaking portfol...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17185</th>\n",
       "      <td>Information &amp; Communication Technology</td>\n",
       "      <td>[our, client, pride, themselves, on, deliverin...</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>software furthermore software consultant revol...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16991</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>[by, joining, this, leading, and, innovative, ...</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>engineering geelong design implemantaion dairy...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28663</th>\n",
       "      <td>Trades &amp; Services</td>\n",
       "      <td>[nobul, trades, is, now, looking, for, number,...</td>\n",
       "      <td>Other</td>\n",
       "      <td>nobul carpentry carpentry every tirelessly day...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10910</th>\n",
       "      <td>Trades &amp; Services</td>\n",
       "      <td>[our, client, is, seeking, multiple, boilermak...</td>\n",
       "      <td>Other</td>\n",
       "      <td>multiple boilermakers commencing immediately a...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12552</th>\n",
       "      <td>Healthcare &amp; Medical</td>\n",
       "      <td>[work, as, casual, days, week, this, will, inc...</td>\n",
       "      <td>Other</td>\n",
       "      <td>pracsoft triaging spirometry ha cdm ecg ear sy...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25093</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>[our, client, are, you, passionate, electrical...</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>electrical career supportive firm firm service...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12152</th>\n",
       "      <td>Administration &amp; Office Support</td>\n",
       "      <td>[want, to, work, for, australiaa, tms, commerc...</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>property real estate wea tmre jll wea tmre rea...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13813</th>\n",
       "      <td>Consulting &amp; Strategy</td>\n",
       "      <td>[wea, tmre, bunch, of, passionate, people, who...</td>\n",
       "      <td>Other</td>\n",
       "      <td>process improvement process wm colonial coloni...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29655 rows Ã— 5 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77ad434a-57fa-4c52-ae55-6d39b3ca5a52')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-77ad434a-57fa-4c52-ae55-6d39b3ca5a52 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-77ad434a-57fa-4c52-ae55-6d39b3ca5a52');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                     category  \\\n",
       "25579              Mining, Resources & Energy   \n",
       "1807                     Healthcare & Medical   \n",
       "17185  Information & Communication Technology   \n",
       "16991                             Engineering   \n",
       "28663                       Trades & Services   \n",
       "...                                       ...   \n",
       "10910                       Trades & Services   \n",
       "12552                    Healthcare & Medical   \n",
       "25093                             Engineering   \n",
       "12152         Administration & Office Support   \n",
       "13813                   Consulting & Strategy   \n",
       "\n",
       "                                         job_description job_type_target  \\\n",
       "25579  [premium, mechanical, group, pmg, is, leading,...       Full Time   \n",
       "1807   [medical, advisor, global, pharma, sydney, gro...       Full Time   \n",
       "17185  [our, client, pride, themselves, on, deliverin...       Full Time   \n",
       "16991  [by, joining, this, leading, and, innovative, ...       Full Time   \n",
       "28663  [nobul, trades, is, now, looking, for, number,...           Other   \n",
       "...                                                  ...             ...   \n",
       "10910  [our, client, is, seeking, multiple, boilermak...           Other   \n",
       "12552  [work, as, casual, days, week, this, will, inc...           Other   \n",
       "25093  [our, client, are, you, passionate, electrical...       Full Time   \n",
       "12152  [want, to, work, for, australiaa, tms, commerc...       Full Time   \n",
       "13813  [wea, tmre, bunch, of, passionate, people, who...           Other   \n",
       "\n",
       "                                       short_description  split  \n",
       "25579  premium pmg plant job premium job employees jo...   test  \n",
       "1807   medical advisor pharma ground breaking portfol...  train  \n",
       "17185  software furthermore software consultant revol...  train  \n",
       "16991  engineering geelong design implemantaion dairy...  train  \n",
       "28663  nobul carpentry carpentry every tirelessly day...   test  \n",
       "...                                                  ...    ...  \n",
       "10910  multiple boilermakers commencing immediately a...  train  \n",
       "12552  pracsoft triaging spirometry ha cdm ecg ear sy...  train  \n",
       "25093  electrical career supportive firm firm service...   test  \n",
       "12152  property real estate wea tmre jll wea tmre rea...  train  \n",
       "13813  process improvement process wm colonial coloni...  train  \n",
       "\n",
       "[29655 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(script_dir + '/data/processed_seek.csv')\n",
    "df['job_description'] = df['job_description'].apply(lambda x: x.split(' ')[:30])\n",
    "df = df.sample(frac=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9yeK-JWRbJR"
   },
   "source": [
    "## Creating classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCqSMoqbR3zc"
   },
   "source": [
    "This ssection creates classes required to train the model. The usual Vocabulary, Vecotrizer and Dataset classes are included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_ry1rzzSGr-"
   },
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xDkur2-TNPY"
   },
   "source": [
    "Voabulary class holds and dictionary that indexes words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ru3Gyd05Ica5"
   },
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "        \"\"\"\n",
    "\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "    def to_serializable(self):\n",
    "        \"\"\" returns a dictionary that can be serialized \"\"\"\n",
    "        return {'token_to_idx': self._token_to_idx}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "            \n",
    "    def add_many(self, tokens):\n",
    "        \"\"\"Add a list of tokens into the Vocabulary\n",
    "        \n",
    "        Args:\n",
    "            tokens (list): a list of string tokens\n",
    "        Returns:\n",
    "            indices (list): a list of indices corresponding to the tokens\n",
    "        \"\"\"\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        \"\"\"\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8LrwYDBTZA8"
   },
   "source": [
    "SequenceVOcabulary object adds useful tokens to a sentence and creates input of common size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m20KHYYCIca6"
   },
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        contents = super(SequenceVocabulary, self).to_serializable()\n",
    "        contents.update({'unk_token': self._unk_token,\n",
    "                         'mask_token': self._mask_token,\n",
    "                         'begin_seq_token': self._begin_seq_token,\n",
    "                         'end_seq_token': self._end_seq_token})\n",
    "        return contents\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYsh5X1pSw8b"
   },
   "source": [
    "### Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkpEUf-IS2oU"
   },
   "source": [
    "Vectorizer class creates a vectorizer object that can coordinate the indexing of the given vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHsec8XfIca8"
   },
   "outputs": [],
   "source": [
    "class DescriptionVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"    \n",
    "    def __init__(self, token_vocab, category_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_vocab (Vocabulary): maps words to integers\n",
    "            category_vocab (Vocabulary): maps nationalities to integers\n",
    "        \"\"\"\n",
    "        self.token_vocab = token_vocab\n",
    "        self.category_vocab = category_vocab\n",
    "\n",
    "    def vectorize(self, Description, vector_length=-1):\n",
    "        \"\"\"Vectorize a description into a vector of observations and targets\n",
    "        \n",
    "        The outputs are the vectorized description split into two vectors:\n",
    "            description[:-1] and description[1:]\n",
    "        At each timestep, the first vector is the observation and the second vector is the target. \n",
    "        \n",
    "        Args:\n",
    "            description (str): the description to be vectorized\n",
    "            vector_length (int): an argument for forcing the length of index vector\n",
    "        Returns:\n",
    "            a tuple: (from_vector, to_vector)\n",
    "            from_vector (numpy.ndarray): the observation vector \n",
    "            to_vector (numpy.ndarray): the target prediction vector\n",
    "        \"\"\"\n",
    "        indices = [self.token_vocab.begin_seq_index] \n",
    "        indices.extend(self.token_vocab.lookup_token(token) for token in Description)\n",
    "        indices.append(self.token_vocab.end_seq_index)\n",
    "\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices) - 1\n",
    "\n",
    "        from_vector = np.empty(vector_length, dtype=np.int64)         \n",
    "        from_indices = indices[:-1]\n",
    "        from_vector[:len(from_indices)] = from_indices\n",
    "        from_vector[len(from_indices):] = self.token_vocab.mask_index\n",
    "\n",
    "        to_vector = np.empty(vector_length, dtype=np.int64)\n",
    "        to_indices = indices[1:]\n",
    "        to_vector[:len(to_indices)] = to_indices\n",
    "        to_vector[len(to_indices):] = self.token_vocab.mask_index\n",
    "        \n",
    "        return from_vector, to_vector\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, description_df):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            description_df (pandas.DataFrame): the description dataset\n",
    "        Returns:\n",
    "            an instance of the DescriptionVectorizer\n",
    "        \"\"\"\n",
    "        token_vocab = SequenceVocabulary()\n",
    "        category_vocab = Vocabulary()\n",
    "\n",
    "        for index, row in description_df.iterrows():\n",
    "            for token in row.job_description:\n",
    "                token_vocab.add_token(token)\n",
    "            category_vocab.add_token(row.category)\n",
    "\n",
    "        return cls(token_vocab, category_vocab)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\"Instantiate the vectorizer from saved contents\n",
    "        \n",
    "        Args:\n",
    "            contents (dict): a dict holding two vocabularies for this vectorizer\n",
    "                This dictionary is created using `vectorizer.to_serializable()`\n",
    "        Returns:\n",
    "            an instance of DescriptionVectorizer\n",
    "        \"\"\"\n",
    "        token_vocab = SequenceVocabulary.from_serializable(contents['token_vocab'])\n",
    "        nat_vocab =  Vocabulary.from_serializable(contents['category_vocab'])\n",
    "\n",
    "        return cls(token_vocab=token_vocab, category_vocab=nat_vocab)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        \"\"\" Returns the serializable contents \"\"\"\n",
    "        return {'token_vocab': self.token_vocab.to_serializable(), \n",
    "                'category_vocab': self.category_vocab.to_serializable()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBwIaBnDRDzs"
   },
   "source": [
    "### The description dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Xvy9Z_e8Wt"
   },
   "source": [
    "Standard class used in other parts of this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ex4IQxQYIca9"
   },
   "outputs": [],
   "source": [
    "class DescriptioneDataset(Dataset):\n",
    "    def __init__(self, description_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            description_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (DescriptionVectorizer): vectorizer instatiated from dataset\n",
    "        \"\"\"\n",
    "        self.description_df = description_df \n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        self._max_seq_length = max(map(len, self.description_df.job_description)) + 2\n",
    "\n",
    "        self.train_df = self.description_df[self.description_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.description_df[self.description_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.description_df[self.description_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size), \n",
    "                             'val': (self.val_df, self.validation_size), \n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "        \n",
    "    @classmethod\n",
    "    def load_df_and_make_vectorizer(cls, description_df):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            description_csv (str): location of the dataset\n",
    "        Returns:\n",
    "            an instance of DescriptionDataset\n",
    "        \"\"\"\n",
    "        \n",
    "        return cls(description_df, DescriptionVectorizer.from_dataframe(description_df))\n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, description_csv, vectorizer_filepath):\n",
    "        \"\"\"Load dataset and the corresponding vectorizer. \n",
    "        Used in the case in the vectorizer has been cached for re-use\n",
    "        \n",
    "        Args:\n",
    "            description_csv (str): location of the dataset\n",
    "            vectorizer_filepath (str): location of the saved vectorizer\n",
    "        Returns:\n",
    "            an instance of DescriptionDataset\n",
    "        \"\"\"\n",
    "        description_df = pd.read_csv(description_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(description_df, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        \"\"\"a static method for loading the vectorizer from file\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
    "        Returns:\n",
    "            an instance of DescriptionVectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return DescriptionVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        \"\"\"saves the vectorizer to disk using json\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location to save the vectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point: (x_data, y_target, class_index)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        from_vector, to_vector = \\\n",
    "            self._vectorizer.vectorize(row.job_description, self._max_seq_length)\n",
    "        \n",
    "        category_index = \\\n",
    "            self._vectorizer.category_vocab.lookup_token(row.category)\n",
    "\n",
    "        return {'x_data': from_vector, \n",
    "                'y_target': to_vector, \n",
    "                'class_index': category_index}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size\n",
    "    \n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyUu3WIdfBXu"
   },
   "source": [
    "## The description generation model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khKkfZb3fQON"
   },
   "source": [
    "The architecture of this model was taken from the week 11 lab on conditional autoencoders. Two embedding layers were used, one for the job description tokens and one for the category token. Then the features are passed over to the gru layer whose vector is transformed into a two dimensional matrix with each row representing a token batch and sequence index. The columns of each row are then the embeddings of that token. This matrix, after running through the linear layer, outpputs the prediction vector for each token. The sampling function defined below utilizes the multinomial function to select indices at a rate proportional to the index's probability. Adding the category embedding layer conditions the output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ych1gccwIcbA"
   },
   "outputs": [],
   "source": [
    "class DescriptionGenerationModel(nn.Module):\n",
    "    def __init__(self, token_embedding_size, token_vocab_size, rnn_hidden_size, num_cat, \n",
    "                 batch_first=True, padding_idx=0, dropout_p=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_embedding_size (int): The size of the token embeddings\n",
    "            token_vocab_size (int): The number of tokens to embed\n",
    "            rnn_hidden_size (int): The size of the RNN's hidden state\n",
    "            batch_first (bool): Informs whether the input tensors will \n",
    "                have batch or the sequence on the 0th dimension\n",
    "            padding_idx (int): The index for the tensor padding; \n",
    "                see torch.nn.Embedding\n",
    "            dropout_p (float): the probability of zeroing activations using\n",
    "                the dropout method.  higher means more likely to zero.\n",
    "        \"\"\"\n",
    "        super(DescriptionGenerationModel, self).__init__()\n",
    "        \n",
    "        self.token_emb = nn.Embedding(num_embeddings=token_vocab_size,\n",
    "                                     embedding_dim=token_embedding_size,\n",
    "                                     padding_idx=padding_idx)\n",
    "        self.cat_emb = nn.Embedding(num_embeddings=num_cat,\n",
    "        embedding_dim=rnn_hidden_size\n",
    "        )\n",
    "\n",
    "        self.rnn = nn.GRU(input_size=token_embedding_size, \n",
    "                          hidden_size=rnn_hidden_size,\n",
    "                          batch_first=batch_first)\n",
    "        self.fc1 = nn.Linear(in_features = rnn_hidden_size, out_features = int(token_vocab_size/4))\n",
    "        self.fc2 = nn.Linear(in_features=int(token_vocab_size/4), \n",
    "                            out_features=token_vocab_size)\n",
    "        \n",
    "        self._dropout_p = dropout_p\n",
    "\n",
    "    def forward(self, x_in, cat_index, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the model\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim)\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, token_vocab_size)\n",
    "        \"\"\"\n",
    "        x_embedded = self.token_emb(x_in)\n",
    "        cat_embedded = self.cat_emb(cat_index).unsqueeze(0)\n",
    "        y_out, _ = self.rnn(x_embedded, cat_embedded)\n",
    "\n",
    "        batch_size, seq_size, feat_size = y_out.shape\n",
    "        y_out = y_out.contiguous().view(batch_size * seq_size, feat_size)\n",
    "        y_out = self.fc1(F.dropout(y_out, p=self._dropout_p))\n",
    "        y_out = self.fc2(y_out)\n",
    "                         \n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out, dim=1)\n",
    "            \n",
    "        new_feat_size = y_out.shape[-1]\n",
    "        y_out = y_out.view(batch_size, seq_size, new_feat_size)\n",
    "            \n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtm97aY0IcbC"
   },
   "outputs": [],
   "source": [
    "def sample_from_model(model, vectorizer, categories, sample_size=20, \n",
    "                      temperature=1.0):\n",
    "    \"\"\"Sample a sequence of indices from the model\n",
    "    \n",
    "    Args:\n",
    "        model (SurnameGenerationModel): the trained model\n",
    "        vectorizer (SurnameVectorizer): the corresponding vectorizer\n",
    "        categories (list): a list of integers representing categories\n",
    "        sample_size (int): the max length of the samples\n",
    "        temperature (float): accentuates or flattens \n",
    "            the distribution. \n",
    "            0.0 < temperature < 1.0 will make it peakier. \n",
    "            temperature > 1.0 will make it more uniform\n",
    "    Returns:\n",
    "        indices (torch.Tensor): the matrix of indices; \n",
    "        shape = (num_samples, sample_size)\n",
    "    \"\"\"\n",
    "    num_samples = len(categories)\n",
    "    begin_seq_index = [vectorizer.token_vocab.begin_seq_index \n",
    "                       for _ in range(num_samples)]\n",
    "    begin_seq_index = torch.tensor(begin_seq_index, \n",
    "                                   dtype=torch.int64).unsqueeze(dim=1)\n",
    "    indices = [begin_seq_index]\n",
    "    category_indices = torch.tensor(categories, dtype=torch.int64).unsqueeze(dim=0)\n",
    "    h_t = model.cat_emb(category_indices)\n",
    "    \n",
    "    for time_step in range(sample_size):\n",
    "        x_t = indices[time_step]\n",
    "        x_emb_t = model.token_emb(x_t)\n",
    "        rnn_out_t, h_t = model.rnn(x_emb_t, h_t)\n",
    "        intermed = model.fc1(rnn_out_t.squeeze(dim=1))\n",
    "        prediction_vector = model.fc2(intermed)\n",
    "        probability_vector = F.softmax(prediction_vector / temperature, dim=1)\n",
    "        indices.append(torch.multinomial(probability_vector, num_samples=1))\n",
    "    indices = torch.stack(indices).squeeze().permute(1, 0)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCysbKUwIcbC"
   },
   "outputs": [],
   "source": [
    "def decode_samples(sampled_indices, vectorizer):\n",
    "    \"\"\"Transform indices into the string form of a Description\n",
    "    \n",
    "    Args:\n",
    "        sampled_indices (torch.Tensor): the inidces from `sample_from_model`\n",
    "        vectorizer (DescriptionVectorizer): the corresponding vectorizer\n",
    "    \"\"\"\n",
    "    decoded_descriptions = []\n",
    "    vocab = vectorizer.token_vocab\n",
    "    \n",
    "    for sample_index in range(sampled_indices.shape[0]):\n",
    "        description = \"\"\n",
    "        for time_step in range(sampled_indices.shape[1]):\n",
    "            sample_item = sampled_indices[sample_index, time_step].item()\n",
    "            if sample_item == vocab.begin_seq_index:\n",
    "                continue\n",
    "            elif sample_item == vocab.end_seq_index:\n",
    "                break\n",
    "            else:\n",
    "                description += ' ' + vocab.lookup_index(sample_item)\n",
    "        decoded_descriptions.append(description)\n",
    "    return decoded_descriptions\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pA3b22EiIcbC"
   },
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        if loss_t >= loss_tm1:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def normalize_sizes(y_pred, y_true):\n",
    "    \"\"\"Normalize tensor sizes\n",
    "    \n",
    "    Args:\n",
    "        y_pred (torch.Tensor): the output of the model\n",
    "            If a 3-dimensional tensor, reshapes to a matrix\n",
    "        y_true (torch.Tensor): the target predictions\n",
    "            If a matrix, reshapes to be a vector\n",
    "    \"\"\"\n",
    "    if len(y_pred.size()) == 3:\n",
    "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
    "    if len(y_true.size()) == 2:\n",
    "        y_true = y_true.contiguous().view(-1)\n",
    "    return y_pred, y_true\n",
    "\n",
    "def compute_accuracy(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    \n",
    "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
    "    valid_indices = torch.ne(y_true, mask_index).float()\n",
    "    \n",
    "    n_correct = (correct_indices * valid_indices).sum().item()\n",
    "    n_valid = valid_indices.sum().item()\n",
    "\n",
    "    return n_correct / n_valid * 100\n",
    "\n",
    "def sequence_loss(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRTi0x1AIcbD"
   },
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1653905739682,
     "user": {
      "displayName": "Omri Ram",
      "userId": "07837710711281572278"
     },
     "user_tz": -120
    },
    "id": "I_5tA1oJIcbD",
    "outputId": "e1c7284f-4922-44fc-cff3-e31e2f79a53a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n"
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "    # Data and Path information\n",
    "    description_csv= script_dir + \"/data/processed_seek.csv\",\n",
    "    model_state_file=script_dir + \"/model_storage/desc_generation.pth\",\n",
    "    save_dir=\"model_storage/model1_unconditioned_description_generation\",\n",
    "    # Model hyper parameters\n",
    "    token_embedding_size=100,\n",
    "    rnn_hidden_size=100,\n",
    "    # Training hyper parameters\n",
    "    seed=1337,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=128,\n",
    "    num_epochs=100,\n",
    "    early_stopping_criteria=5,\n",
    "    # Runtime options\n",
    "    catch_keyboard_interrupt=True,\n",
    "    cuda=True,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    "    reload_from_files=False,\n",
    ")   \n",
    "    \n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2112,
     "status": "ok",
     "timestamp": 1653905744002,
     "user": {
      "displayName": "Omri Ram",
      "userId": "07837710711281572278"
     },
     "user_tz": -120
    },
    "id": "xPghJVUeNtd_",
    "outputId": "bc38a0a4-dd7e-4bfa-c023-bb6813371e58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DescriptioneDataset.load_df_and_make_vectorizer(df)\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "len(vectorizer.category_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8muvgTcIcbE"
   },
   "outputs": [],
   "source": [
    "dataset = DescriptioneDataset.load_df_and_make_vectorizer(df)\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "model = DescriptionGenerationModel(token_embedding_size=args.token_embedding_size,\n",
    "                               token_vocab_size=len(vectorizer.token_vocab),\n",
    "                               num_cat=len(vectorizer.category_vocab),\n",
    "                               rnn_hidden_size=args.rnn_hidden_size,\n",
    "                               padding_idx=vectorizer.token_vocab.mask_index,\n",
    "                               dropout_p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1653905747226,
     "user": {
      "displayName": "Omri Ram",
      "userId": "07837710711281572278"
     },
     "user_tz": -120
    },
    "id": "QyEcCP0lNteA",
    "outputId": "79af3b5e-bd08-4c01-ea65-d6c32ec5c1b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19294"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = dataset.get_vectorizer()\n",
    "vocab_dict =  vec.token_vocab.to_serializable()\n",
    "len(vocab_dict['token_to_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "ff21a5d53c44421191fe0ff920b2b092",
      "7965906a2f44447cbc4d97906c7a621e",
      "981280f03ca747cb9011c1ef24246bfb",
      "0101d5372a58412aaf0a0ca6e96e2eba",
      "6279d458a915409eaa985775a7acc783",
      "a6fe7854ba5c4c43860759402b8cf600",
      "19bcfc020ef945b5a4155d7f99946465",
      "be81fe065b874d05b8c61480b04aad49",
      "73cfc5c8d8c2481c8579e4722d2766cf",
      "b80da48b57f94f839b388d134178d863",
      "5574d50786bd4314aa98bd8bce8494f7",
      "d5fdb294bcd54149bd250bada61f1066",
      "2a5f3f3b78384249921e682d8fd1ee7e",
      "86e89cbc9bba4a6c8dbe93adb74d3a4b",
      "cef46b98a115447692fe121cc4384b87",
      "e3fb838375d94e76a4d99a7f37f2d156",
      "0138380645314b6f97af6f2d343ed8ac",
      "feedab2fca79439c818ccab920a73a14",
      "cdddc1c8a3114357ace34efac79658d8",
      "3ac5503e9c2a47b4995f90395e8db427",
      "1dc77e043d224b4b93308322e26b8419",
      "eb73171640624e8682f25be084a3f2c3",
      "6cd701eae2d5434fa3fdec026f8d1c14",
      "c887f86d696b40a18170bb414d6b2ee0",
      "45bf91ddb5c6447b975c5e53850480c0",
      "4ffa69d670544298b56d20454fc82dd5",
      "a3a7bafa1739439fa4a40418d7e8137b",
      "0a40187ba8a7469aa87146bfd70cbf43",
      "169abb8f475c4904aba18485ad988c62",
      "b19b0bd6e75346548e8620b8e8d744b2",
      "59bb0d8c35094a7e9c4e753f116b83ec",
      "6eea2ebe0ecc445eb4026c71dc8f5a7a",
      "631ac8cfb20840b9bd7c44128ab9ce5d"
     ]
    },
    "id": "DZIWbLXxIcbE",
    "outputId": "817f6b14-3bd7-49d4-d52a-4b8eae9317b5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff21a5d53c44421191fe0ff920b2b092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training routine:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fdb294bcd54149bd250bada61f1066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=train:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd701eae2d5434fa3fdec026f8d1c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=val:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "mask_index = vectorizer.token_vocab.mask_index\n",
    "\n",
    "model = model.to(args.device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                           mode='min', factor=0.5,\n",
    "                                           patience=1)\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', \n",
    "                          total=args.num_epochs,\n",
    "                          position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train',\n",
    "                          total=dataset.get_num_batches(args.batch_size), \n",
    "                          position=1, \n",
    "                          leave=True)\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val',\n",
    "                        total=dataset.get_num_batches(args.batch_size), \n",
    "                        position=1, \n",
    "                        leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------    \n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = model(x_in=batch_dict['x_data'], \n",
    "                           cat_index = batch_dict['class_index'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
    "\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the  running loss and running accuracy\n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss,\n",
    "                                  acc=running_acc,\n",
    "                                  epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        model.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # compute the output\n",
    "            y_pred = model(x_in=batch_dict['x_data'], \n",
    "                           cat_index=batch_dict['class_index'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
    "\n",
    "            # compute the  running loss and running accuracy\n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            \n",
    "            # Update bar\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
    "                            epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=model, \n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "            \n",
    "        # move model to cpu for sampling\n",
    "        \n",
    "        categories = np.random.choice(np.arange(len(vectorizer.category_vocab)), replace=True, size=2)\n",
    "        model = model.cpu()\n",
    "        samples_descs = decode_samples(\n",
    "            sample_from_model(model, vectorizer, categories), \n",
    "            vectorizer)\n",
    "        \n",
    "        sample1 = \"{}->{}\".format(vectorizer.category_vocab.lookup_index(categories[0]), \n",
    "                                  categories[0])\n",
    "        sample2 = \"{}->{}\".format(vectorizer.category_vocab.lookup_index(categories[1]), \n",
    "                                  categories[1])\n",
    "        epoch_bar.set_postfix(sample1=sample1, \n",
    "                              sample2=sample2)\n",
    "        # move model back to whichever device it should be on\n",
    "        model = model.to(args.device)\n",
    "        \n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3nZtI6sDNteB",
    "outputId": "66c5c045-aacc-46d2-811b-f91795e73ecc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 4.712231905564018;\n",
      "Test Accuracy: 28.55841762551177\n"
     ]
    }
   ],
   "source": [
    "# compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "model.load_state_dict(torch.load(train_state['model_filename']))\n",
    "\n",
    "model = model.to(args.device)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_acc = 0.\n",
    "model.eval()\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred = model(x_in=batch_dict['x_data'], \n",
    "                   cat_index=batch_dict['class_index'])\n",
    "\n",
    "    # compute the loss\n",
    "    loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
    "    \n",
    "    # compute the running loss and running accuracy\n",
    "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss \n",
    "train_state['test_acc'] = running_acc \n",
    "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
    "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fl-vhViHSYfb",
    "outputId": "74e4529e-0402-4236-fb7d-22fa4423ae4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled for Manufacturing, Transport & Logistics: \n",
      "-   the company our client is global leader in the market and residential aluminium is seeking an experienced customer service technician\n",
      "-   our client is premier food manufacturer of joinery products in the civil construction and industry we are currently seeking an\n",
      "-   the company this company has been established in the country for over years in the safe and the industry with\n",
      "-   casual position looking for an experienced construction diesel fitters to join our team to be considered for this role you\n",
      "-   the company well established retailer to the market the business leading and customer service and customer service team our client\n",
      "\n",
      "\n",
      "Sampled for Accounting: \n",
      "-   the company this is an exciting opportunity to join their business friendly business in the perth area this role has\n",
      "-   the company our client is dynamic and well known national company based in the sydney cbd require an experienced events\n",
      "-   the role my client provides financial planning advice and financial services and have long established in sydney to join our\n",
      "-   the role we are leading provider of and australian owned business and development and services care based in the inner\n",
      "-   tired of traveling to grow your new company this global engineering company is looking for an experienced project manager with\n",
      "\n",
      "\n",
      "Sampled for Engineering: \n",
      "-   our client is global market leader in the manufacture of manufacture and supply services in the construction and construction industry\n",
      "-   about the business the role the role the role will provide the support in on the responsible for scheduling and\n",
      "-   about the company our client large reputable company in the australian market due to expansion they are seeking an experienced\n",
      "-   the company this mid tier consultancy is leading business that has the reputation of our client is leading innovative commercial\n",
      "-   our client market leader in design building is seeking an experienced and experienced diesel technician for the role this role\n",
      "\n",
      "\n",
      "Sampled for Sales: \n",
      "-   location parkinson company is looking for highly experienced experienced the business and we have an opportunity for an experienced property\n",
      "-   leading fmcg company based in hornsby and manages an exciting opportunity to join the team of highly skilled government team\n",
      "-   australian owned and operated manufacturing group we are looking for qualified and enthusiastic customer service who are looking for our\n",
      "-   one of australia largest automotive provider in the food industry the company is looking for senior account manager to join\n",
      "-   permanent full time position immediate start for the best day shift with an immediate start for the right candidate must\n",
      "\n",
      "\n",
      "Sampled for Call Centre & Customer Service: \n",
      "-   the company our client is well known and progressive company based in sydney cbd listed and national clients with an\n",
      "-   about the company we are family owned family business that has been in the global market they are now looking\n",
      "-   marketing and professional career development and work for national organisation in australia the role the purpose of the position is\n",
      "-   about the company our client is looking for an experienced accounts payable officer to join our team to be considered\n",
      "-   about the business this role is leading global fmcg with minimum of years experience and is growing aggressively and delivering\n",
      "\n",
      "\n",
      "Sampled for Healthcare & Medical: \n",
      "-   our client is leading organisation with an excellent reputation for the and quality home care for our clients in the\n",
      "-   our client is leading provider of recruitment services to the world leader and providing the highest quality service and services\n",
      "-   an exciting opportunity exists for motivated individuals to join our team of the entire medical care team at the heart\n",
      "-   about the company our client is an excellent opportunity for an experienced and clinical nurse to assist the and administration\n",
      "-   we are seeking an experienced dental assistant to join our team within the northern suburbs of this role you will\n",
      "\n",
      "\n",
      "Sampled for Hospitality & Tourism: \n",
      "-   restaurant in panania is seeking casual cafe all rounder up to hours per week to join our team to be\n",
      "-   about us the morrison food and is one of australia fastest growing automotive management and company in the national rooms\n",
      "-   cafe in the eastern suburbs is seeking experienced casual barista up to hours per week to join our team to\n",
      "-   about the business we are seeking additional trainers and is for the food and beverage team of the business and\n",
      "-   restaurant in newtown is seeking full time barista up to hours per week to join our team to be considered\n",
      "\n",
      "\n",
      "Sampled for Construction: \n",
      "-   the company this company is well regarded and established company with over years and employs over staff to their clients\n",
      "-   residential care projects across dandenong are you an experienced payroll officer to join their team and based in the northern\n",
      "-   supporting both major company we have the reputation for the trade commercial and domestic and commercial and construction industries we\n",
      "-   our client is seeking an experienced project manager to join their growing team on the sunshine coast the market industry\n",
      "-   our client is an industry leading privately owned recruitment recruitment company with over years of experience in their industry due\n",
      "\n",
      "\n",
      "Sampled for Trades & Services: \n",
      "-   our client is an industry leader in the and construction industry with over years of strong experience in the construction\n",
      "-   am pm and labour hire is seeking an experienced energetic and qualified specialist to join our dynamic team at our\n",
      "-   mechanical services group is an experienced infrastructure project manager company based in perth australia is seeking an experienced microstation experience\n",
      "-   immediate start our client is global company with over years our client and has been supplying crane and power and\n",
      "-   the role the role is world class and bulk water logistics business for the largest mining mining and construction service\n",
      "\n",
      "\n",
      "Sampled for Education & Training: \n",
      "-   anzuk education and has been in the business of the community for the past years we are looking for and\n",
      "-   about the business and the role charred agency is designed to deliver high quality and affordable and accessible keep reading\n",
      "-   our school is and we currently have full time opportunity to join our friendly team and an interesting role and\n",
      "-   our client is recognised as professional provider of high profile company and fun and busy and supportive culture currently looking\n",
      "-   classification anu officer grade all permanent part time positions available attractive salary super central coast fixed term full time position\n",
      "\n",
      "\n",
      "Sampled for Legal: \n",
      "-   this is great opportunity for position administrator for the corporate role with the contract opportunity for casual work in part\n",
      "-   the role we are currently looking for an experienced general payroll manager to join our team to be considered for\n",
      "-   are you an experienced legal secretary to join our team as successful candidate will be able to work on high\n",
      "-   the role our client is an innovative boutique firm in an established in the delivery of our clients our client\n",
      "-   at amicus not just staff we are seeking an experienced business analyst with general communications officer to join their team\n",
      "\n",
      "\n",
      "Sampled for Insurance & Superannuation: \n",
      "-   we are the an independent organisation of the information technology and technology services and job it is leading and managed\n",
      "-   the role the role will be the lead commercial specialist as in the role management on the provision of the\n",
      "-   our client is highly regarded market leading provider of market leader and providing high end senior and accurate solutions to\n",
      "-   our client is leading financial planning firm looking for highly skilled senior architect who are looking for an initial month\n",
      "-   the role our client is leading well established organisation with over years and experience in their field are currently seeking\n",
      "\n",
      "\n",
      "Sampled for Real Estate & Property: \n",
      "-   about the role our client is an independent privately owned business to be part of just with media this role\n",
      "-   about the role this is great opportunity for an energetic and motivated sales manager in our environment in the sydney\n",
      "-   the role is an established and highly progressive and progressive firm the company is looking for an experienced and professional\n",
      "-   the role on support to the hospitality an industry leader in business and new business we offer an immediate start\n",
      "-   this is one of the leading property and management management accountant our client is looking for an enthusiastic individual to\n",
      "\n",
      "\n",
      "Sampled for Advertising, Arts & Media: \n",
      "-   about the company role we are looking for an experienced growth and senior support officer to join our team this\n",
      "-   the premier group is seeking an experienced digital marketing coordinator to join our busy team in new region the role\n",
      "-   about the business and the business is the largest independent distributor of digital business with over stores and the remarkable\n",
      "-   at the world we are committed to our people and we take the step in our business and grow your\n",
      "-   we are looking for an early childhood manager to join our team as part of our growing team in the\n",
      "\n",
      "\n",
      "Sampled for Information & Communication Technology: \n",
      "-   based in the sydney cbd based in the cbd the role is fantastic opportunity to join this global organisation based\n",
      "-   our client is an australian owned company that have delivered service and sectors they have an opportunity to be part\n",
      "-   this is an exciting opportunity for an experienced project manager to join their team as an integral part of the\n",
      "-   about the business and the role is an exciting opportunity for an experienced reception analyst with strong background to work\n",
      "-   design and data delivery is our client is seeking an experienced technical business and data analyst to join the team\n",
      "\n",
      "\n",
      "Sampled for Consulting & Strategy: \n",
      "-   aurecon is exciting opportunity to join our competitive salary package at killer kicks and the opportunity to be leader in\n",
      "-   do you want to work in the following and secure the business in the role of the position is currently\n",
      "-   on the role of this role you will be required to join the marketing team at senior advisor hr role\n",
      "-   about the company the company market leader in the management and service of the the market our client is looking\n",
      "-   our client is an enthusiastic and committed to the business and marketing technical expertise for an australian owned and operated\n",
      "\n",
      "\n",
      "Sampled for Mining, Resources & Energy: \n",
      "-   we are currently seeking experienced civil labourers for several project fifo and work on major local government industry this is\n",
      "-   our client is leading manufacturer of building and construction services as well as the global leader and providing customer service\n",
      "-   we are currently seeking an experienced supervisor with experience to be part of high end and residential commercial construction projects\n",
      "-   join our team of the opportunity for an experienced project manager to join the team in the north australia they\n",
      "-   our client is leading logistics company with an extensive experience in the design engineering and delivery of the mining construction\n",
      "\n",
      "\n",
      "Sampled for Government & Defence: \n",
      "-   super fixed term contract in darwin and experience preferred work with organisation development or work in the industry the role\n",
      "-   today we have around people who work to help make sure medicare and the pbs is used well by july\n",
      "-   we are currently seeking an experienced permanent full time and continuing to work in the community who are looking for\n",
      "-   our client is seeking an experienced senior manager to join their team the role as part of our team lead\n",
      "-   today we have around people who work to make sure medicare and the pbs is used well by july this\n",
      "\n",
      "\n",
      "Sampled for Administration & Office Support: \n",
      "-   our client is leading global company that is fantastic opportunity to join highly regarded and growing organisation who are we\n",
      "-   new opportunity for an experienced payroll officer to join our team you will be responsible for the provision of the\n",
      "-   this role is the role to join our technology team that is an the exciting opportunity for an experienced and\n",
      "-   about the organisation our client is leading provider of business services which has been in the market and provide more\n",
      "-   the role the company is one of the most recognised brand new and modern offices in the sydney cbd are\n",
      "\n",
      "\n",
      "Sampled for Community Services & Development: \n",
      "-   this purpose of an exciting opportunity exists for an experienced senior pmo officer to join our team environment this role\n",
      "-   about the role our community is working closely with rapidly growing regular and diverse range of practices in the months\n",
      "-   about the business our client has been operating for over years in the australian market is seeking an experienced and\n",
      "-   about us the opportunity we are currently recruiting for an experienced staff to join the team to be considered for\n",
      "-   the company our client provides many diverse multi plus and wide and range of industries across the nt and to\n",
      "\n",
      "\n",
      "Sampled for Retail & Consumer Products: \n",
      "-   in australia we are looking for an experienced and experienced sales consultant who is looking for the next challenge of\n",
      "-   this is an opportunity for an enthusiastic role that is looking to join our team and it takes pride providing\n",
      "-   is an exciting opportunity for an experienced store manager to join the team on maternity leave basis network and our\n",
      "-   fantastic opportunity to join an excellent opportunity to be part of an exciting team you will be looking for an\n",
      "-   we are looking for an experienced handyman to join our team of dedicated and experienced sales representatives to assist with\n",
      "\n",
      "\n",
      "Sampled for Human Resources & Recruitment: \n",
      "-   our client is an australian leader in the and economic development of the commercial industrial industry and our client is\n",
      "-   the company this is tax opportunity to join the business development and cyber security products sales team with the successful\n",
      "-   this is an exciting opportunity for an experienced senior senior communications officer to join our team to the right candidate\n",
      "-   competitive salary super based in sydneya tms cbd this is hands on opportunity for number of an established and innovative\n",
      "-   work for national advisory firm our client is global leader in the services in the australian market we are seeking\n",
      "\n",
      "\n",
      "Sampled for Banking & Financial Services: \n",
      "-   senior advisor month contract your new company this an established organisation is looking for experienced and skilled workers to join\n",
      "-   this leading financial services firm has been operating for over years and has been seeking the past years and multiple\n",
      "-   the company our client is global investment firm the practice is the leading media provider of insurance business they are\n",
      "-   the westpac group is the leading provider of specialist business analyst and industry with the best unsw of the point\n",
      "-   the company our client is an industry leader in the industry in the market in the legal industry offers an\n",
      "\n",
      "\n",
      "Sampled for Marketing & Communications: \n",
      "-   about the business we are looking for an experienced and talented individual to join our sales team at the heart\n",
      "-   about the business the role reporting to the store manager you will be responsible for the and effective of operational\n",
      "-   the company mercator and is an australian owned and operated company providing services to key maintenance and the ideal and\n",
      "-   about us we are an australian owned business in the australian market of air conditioning and refrigeration group will be\n",
      "-   about the business this successful organisation is looking for accounts payable officer to join their growing team as well as\n",
      "\n",
      "\n",
      "Sampled for Design & Architecture: \n",
      "-   opportunity to work for one of melbourne leading builders in australia our client is looking for an experienced team to\n",
      "-   about the company our client is currently looking for an experienced data analyst to join their team on the hunt\n",
      "-   about the company our client is leading tier company with an experienced team of data and systems for the business\n",
      "-   the business which is leading retail team they have requirement for an experienced senior customer service manager to join their\n",
      "-   we are currently seeking an experienced management and experienced customer service officer to join their team of an energetic on\n",
      "\n",
      "\n",
      "Sampled for Science & Technology: \n",
      "-   your new company this is unique opportunity for an experienced hr to join global team in the cbd reporting to\n",
      "-   the company intertek is support services and is one of australia leading providers of talent to source of the top\n",
      "-   will provide services to the pre delivery of the effective operational and delivery of the activities of the structural product\n",
      "-   about the business and the client is an established and national team in the early learning and manufacturing industry we\n",
      "-   competitive remuneration package monday friday am pm full time position excellent environment location about the business we are seeking an\n",
      "\n",
      "\n",
      "Sampled for CEO & General Management: \n",
      "-   the role is an exciting opportunity to join the leading provider of the business for months this role is an\n",
      "-   about the company the global leader in the field of family services and business is an established for its clients\n",
      "-   experience and experience and based in the heart of our sydney we are an opportunity to join our team to\n",
      "-   do you have new and experienced customer service and proven skills and experience in the technology fast paced environment and\n",
      "-   about the business and the role the department of and education is one of australiaa tms leading construction and public\n",
      "\n",
      "\n",
      "Sampled for Farming, Animals & Conservation: \n",
      "-   am about the role we are currently seeking an experienced barista up to hours per week to join our team\n",
      "-   our client is seeking well presented and motivated person to join our team we are looking for an experienced and\n",
      "-   this role you will be responsible for providing training solutions for the delivery of our clients in the australian and\n",
      "-   the are you the best people with you knowledge in the industry we are currently seeking about the role as\n",
      "-   about us the opportunity as well as the dealership in the brisbane city of and this position is looking for\n",
      "\n",
      "\n",
      "Sampled for Sport & Recreation: \n",
      "-   about the business which is the best in early childhood early childhood learning centres are seeking full time ongoing training\n",
      "-   about the business the role is the an exciting performance of position that is responsible for the management of the\n",
      "-   about the business and we are currently seeking co ordinator to join their team for an enthusiastic and experienced an\n",
      "-   we are currently seeking experienced professional and energetic individual with experience in key prime and key support to the hills\n",
      "-   work life balance is responsible for the world for the right digital clients for producing diverse and range of products\n",
      "\n",
      "\n",
      "Sampled for Self Employment: \n",
      "-   about the business the role involves quality of the warehouse and welding team for the container of earthmoving and production\n",
      "-   salesman ia tmm we are looking for an experienced and talented senior senior hairdresser for looking for talented individual to\n",
      "-   we have an opportunity to join our team in our brand new south south west of melbourne we have number\n",
      "-   about the role the company this global leading company is an innovative supplier of and high quality and environmental services\n",
      "-   about the business and the role is reporting to the business and manager strategies and hands on the gold coast\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.cpu()\n",
    "for index in range(len(vectorizer.category_vocab)):\n",
    "    category = vectorizer.category_vocab.lookup_index(index)\n",
    "    print(\"Sampled for {}: \".format(category))\n",
    "    sampled_indices = sample_from_model(model, vectorizer,  \n",
    "                                        categories=[index] * 5, \n",
    "                                        temperature=0.7)\n",
    "    for sampled_surname in decode_samples(sampled_indices, vectorizer):\n",
    "        print(\"-  \" + sampled_surname)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "description_generation (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3931f8ce93702ec92af21f632a7247673a82decd980a4ceb2171679cfa65979b"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0101d5372a58412aaf0a0ca6e96e2eba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b80da48b57f94f839b388d134178d863",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5574d50786bd4314aa98bd8bce8494f7",
      "value": " 71/100 [1:07:37&lt;27:21, 56.60s/it, sample1=Real Estate &amp; Property-&gt;12, sample2=Construction-&gt;7]"
     }
    },
    "0138380645314b6f97af6f2d343ed8ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a40187ba8a7469aa87146bfd70cbf43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "169abb8f475c4904aba18485ad988c62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "19bcfc020ef945b5a4155d7f99946465": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1dc77e043d224b4b93308322e26b8419": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a5f3f3b78384249921e682d8fd1ee7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0138380645314b6f97af6f2d343ed8ac",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_feedab2fca79439c818ccab920a73a14",
      "value": "split=train:  99%"
     }
    },
    "3ac5503e9c2a47b4995f90395e8db427": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "45bf91ddb5c6447b975c5e53850480c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b19b0bd6e75346548e8620b8e8d744b2",
      "max": 23,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_59bb0d8c35094a7e9c4e753f116b83ec",
      "value": 17
     }
    },
    "4ffa69d670544298b56d20454fc82dd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6eea2ebe0ecc445eb4026c71dc8f5a7a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_631ac8cfb20840b9bd7c44128ab9ce5d",
      "value": " 17/23 [1:23:38&lt;00:00,  7.95it/s, acc=28.3, epoch=87, loss=4.73]"
     }
    },
    "5574d50786bd4314aa98bd8bce8494f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59bb0d8c35094a7e9c4e753f116b83ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6279d458a915409eaa985775a7acc783": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "631ac8cfb20840b9bd7c44128ab9ce5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6cd701eae2d5434fa3fdec026f8d1c14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c887f86d696b40a18170bb414d6b2ee0",
       "IPY_MODEL_45bf91ddb5c6447b975c5e53850480c0",
       "IPY_MODEL_4ffa69d670544298b56d20454fc82dd5"
      ],
      "layout": "IPY_MODEL_a3a7bafa1739439fa4a40418d7e8137b"
     }
    },
    "6eea2ebe0ecc445eb4026c71dc8f5a7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73cfc5c8d8c2481c8579e4722d2766cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7965906a2f44447cbc4d97906c7a621e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6fe7854ba5c4c43860759402b8cf600",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_19bcfc020ef945b5a4155d7f99946465",
      "value": "training routine:  71%"
     }
    },
    "86e89cbc9bba4a6c8dbe93adb74d3a4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdddc1c8a3114357ace34efac79658d8",
      "max": 162,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3ac5503e9c2a47b4995f90395e8db427",
      "value": 161
     }
    },
    "981280f03ca747cb9011c1ef24246bfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be81fe065b874d05b8c61480b04aad49",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_73cfc5c8d8c2481c8579e4722d2766cf",
      "value": 71
     }
    },
    "a3a7bafa1739439fa4a40418d7e8137b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6fe7854ba5c4c43860759402b8cf600": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b19b0bd6e75346548e8620b8e8d744b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b80da48b57f94f839b388d134178d863": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be81fe065b874d05b8c61480b04aad49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c887f86d696b40a18170bb414d6b2ee0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a40187ba8a7469aa87146bfd70cbf43",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_169abb8f475c4904aba18485ad988c62",
      "value": "split=val:  74%"
     }
    },
    "cdddc1c8a3114357ace34efac79658d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cef46b98a115447692fe121cc4384b87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dc77e043d224b4b93308322e26b8419",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_eb73171640624e8682f25be084a3f2c3",
      "value": " 161/162 [1:23:36&lt;00:00,  2.97it/s, acc=32.7, epoch=87, loss=3.73]"
     }
    },
    "d5fdb294bcd54149bd250bada61f1066": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2a5f3f3b78384249921e682d8fd1ee7e",
       "IPY_MODEL_86e89cbc9bba4a6c8dbe93adb74d3a4b",
       "IPY_MODEL_cef46b98a115447692fe121cc4384b87"
      ],
      "layout": "IPY_MODEL_e3fb838375d94e76a4d99a7f37f2d156"
     }
    },
    "e3fb838375d94e76a4d99a7f37f2d156": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb73171640624e8682f25be084a3f2c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "feedab2fca79439c818ccab920a73a14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff21a5d53c44421191fe0ff920b2b092": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7965906a2f44447cbc4d97906c7a621e",
       "IPY_MODEL_981280f03ca747cb9011c1ef24246bfb",
       "IPY_MODEL_0101d5372a58412aaf0a0ca6e96e2eba"
      ],
      "layout": "IPY_MODEL_6279d458a915409eaa985775a7acc783"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
