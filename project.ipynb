{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RamOmri/cits4012-project2/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Set your working directory to a folder in your Google Drive. This way, if your notebook times out,\n",
        "# your files will be saved in your Google Drive!\n",
        "\n",
        "# the base Google Drive directory\n",
        "root_dir = \"/content/drive/My Drive/\"\n",
        "\n",
        "# choose where you want your project files to be saved\n",
        "project_folder = \"remote_proj\"\n",
        "\n",
        "def create_and_set_working_directory(project_folder):\n",
        "  # check if your project folder exists. if not, it will be created.\n",
        "  if os.path.isdir(root_dir + project_folder) == False:\n",
        "    os.mkdir(root_dir + project_folder)\n",
        "    print(root_dir + project_folder + ' did not exist but was created.')\n",
        "\n",
        "  # change the OS to use your project folder as the working directory\n",
        "  os.chdir(root_dir + project_folder)\n",
        "\n",
        "  # create a test file to make sure it shows up in the right place\n",
        "  !touch 'new_file_in_working_directory.txt'\n",
        "  print('\\nYour working directory was changed to ' + root_dir + project_folder + \\\n",
        "        \"\\n\\nAn empty text file was created there. You can also run !pwd to confirm the current working directory.\" )\n",
        "\n",
        "create_and_set_working_directory(project_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8etC4Vvx_oA",
        "outputId": "242b8f5e-98f9-4b72-e8fd-bbc8033478a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "Your working directory was changed to /content/drive/My Drive/remote_proj\n",
            "\n",
            "An empty text file was created there. You can also run !pwd to confirm the current working directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ftfy\n",
        "import ftfy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBF2mrUD0GQL",
        "outputId": "4e5c6550-ddf8-454f-d129-1e316d5ff62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (6.1.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Mwlfy8Jx2up"
      },
      "source": [
        "# NLP Project 2, Seek dataset Category and Job Type Classification\n",
        "22274048, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZJLyrQRx2wX"
      },
      "source": [
        "First, import all required libraries and modules for the project and load the data into pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNV7VGiP0W_N",
        "outputId": "51303dd4-d418-45d5-902f-5971e081c3e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoI4rcGCx2wp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "from collections import Counter\n",
        "import string\n",
        "from argparse import Namespace\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "import os\n",
        "import torch.optim as optim\n",
        "import json\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import Word2Vec\n",
        "import seaborn as sns\n",
        "from time import time\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.io import output_notebook\n",
        "from bokeh.models import ColumnDataSource, LabelSet\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.io import output_notebook\n",
        "from bokeh.models import ColumnDataSource, LabelSet\n",
        "from nltk.corpus import stopwords\n",
        "from tqdm.notebook import tqdm\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import KeyedVectors\n",
        "stopwords = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo33QzS_x2w8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "496ebee4-8681-4102-8592-1989c980f761"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1SN-8It-Z6Sun4CATVH-ShCfzdUAuexhH/remote_proj'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "script_dir = os.path.dirname(os.path.realpath('__file__'))\n",
        "script_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnsn9qtvx2xM"
      },
      "outputs": [],
      "source": [
        "df_args = Namespace(\n",
        "    unprocessed_csv  = os.path.join(script_dir, 'data/seek_australia.csv'),\n",
        "    processed_csv = os.path.join(script_dir, 'data/processed_seek.csv'),\n",
        "    train_proportion=0.7,\n",
        "    val_proportion=0.1,\n",
        "    test_proportion=0.2,\n",
        "    frac = 1, # change to 1 to use the full dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZjLne_Xx2xz",
        "outputId": "e91cc00a-9cb3-495b-d90a-02edac9c7726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     category                            city  \\\n",
              "0                           Trades & Services    Newcastle, Maitland & Hunter   \n",
              "1        Manufacturing, Transport & Logistics                          Sydney   \n",
              "2            Community Services & Development  Katherine & Northern Australia   \n",
              "3                      Real Estate & Property                          Sydney   \n",
              "4                       Hospitality & Tourism              Cairns & Far North   \n",
              "...                                       ...                             ...   \n",
              "29995  Information & Communication Technology                          Sydney   \n",
              "29996                       Trades & Services                       Melbourne   \n",
              "29997                                   Sales                       Melbourne   \n",
              "29998                            Construction                          Sydney   \n",
              "29999                    Education & Training                       Melbourne   \n",
              "\n",
              "                             company_name geo job_board  \\\n",
              "0      The Local Bloke Lawn & Garden Care  AU      seek   \n",
              "1                B&J City Kitchen Pty Ltd  AU      seek   \n",
              "2          YMCA of the Northern Territory  AU      seek   \n",
              "3                                   Dexus  AU      seek   \n",
              "4                    Hays Trades & Labour  AU      seek   \n",
              "...                                   ...  ..       ...   \n",
              "29995         Hays Information Technology  AU      seek   \n",
              "29996         Zoom Recruitment & Training  AU      seek   \n",
              "29997                     Recruitmore VIC  AU      seek   \n",
              "29998                   Hays Construction  AU      seek   \n",
              "29999                     anzuk Education  AU      seek   \n",
              "\n",
              "                                         job_description  \\\n",
              "0       Newcastle Location Car License Required Previ...   \n",
              "1       Beak & Johnston are industry leaders within t...   \n",
              "2       The Opportunity Do you enjoy a challenge, lov...   \n",
              "3       Work on one of the best property portfolios i...   \n",
              "4       Permanent position on offer for a Junior Sous...   \n",
              "...                                                  ...   \n",
              "29995   Junior .Net Developer required for a start-up...   \n",
              "29996   We are seeking general labourers/ hands for v...   \n",
              "29997   No industry experience? No worries! Use your ...   \n",
              "29998   This large building construction firm are loo...   \n",
              "29999  anzukÂ is an education services company, that ...   \n",
              "\n",
              "                                             job_title         job_type  \\\n",
              "0                          Lawn & Garden Care Position  Casual/Vacation   \n",
              "1                Machine Operator - Food Manufacturing        Full Time   \n",
              "2                               Youth Diversion Worker        Full Time   \n",
              "3      Communications and Investor Development Manager        Full Time   \n",
              "4                                     Junior Sous Chef        Full Time   \n",
              "...                                                ...              ...   \n",
              "29995                            Junior .Net Developer    Contract/Temp   \n",
              "29996                                General Labourers    Contract/Temp   \n",
              "29997      IMMEDIATE STARTS - SALES & CUSTOMER SERVICE    Contract/Temp   \n",
              "29998                   Senior Contract Administrator         Full Time   \n",
              "29999                                 Japanese Teacher    Contract/Temp   \n",
              "\n",
              "                  post_date                         salary_offered  \\\n",
              "0      2018-04-16T01:15:22Z                                    NaN   \n",
              "1      2018-04-13T03:00:07Z                                    NaN   \n",
              "2      2018-04-11T03:50:48Z                                    NaN   \n",
              "3      2018-04-15T23:10:56Z                                    NaN   \n",
              "4      2018-04-12T02:07:23Z                                    NaN   \n",
              "...                     ...                                    ...   \n",
              "29995  2018-04-13T06:19:44Z                                    NaN   \n",
              "29996  2018-04-16T06:42:38Z                                    NaN   \n",
              "29997  2018-04-14T23:00:07Z                                    NaN   \n",
              "29998  2018-04-16T02:44:21Z                                    NaN   \n",
              "29999  2018-04-11T04:01:04Z  $305+ per day depending on experience   \n",
              "\n",
              "                                   state                                   url  \n",
              "0                                    NaN  https://www.seek.com.au/job/35990983  \n",
              "1           Parramatta & Western Suburbs  https://www.seek.com.au/job/35978566  \n",
              "2                                    NaN  https://www.seek.com.au/job/35957875  \n",
              "3      CBD, Inner West & Eastern Suburbs  https://www.seek.com.au/job/35989342  \n",
              "4                                    NaN  https://www.seek.com.au/job/35967182  \n",
              "...                                  ...                                   ...  \n",
              "29995  CBD, Inner West & Eastern Suburbs  https://www.seek.com.au/job/35982781  \n",
              "29996    Bayside & South Eastern Suburbs  https://www.seek.com.au/job/35997078  \n",
              "29997                CBD & Inner Suburbs  https://www.seek.com.au/job/35987014  \n",
              "29998  CBD, Inner West & Eastern Suburbs  https://www.seek.com.au/job/35992778  \n",
              "29999                                NaN  https://www.seek.com.au/job/35958118  \n",
              "\n",
              "[30000 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce98d964-64f1-45f1-a1b4-7ed3c212efcd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>city</th>\n",
              "      <th>company_name</th>\n",
              "      <th>geo</th>\n",
              "      <th>job_board</th>\n",
              "      <th>job_description</th>\n",
              "      <th>job_title</th>\n",
              "      <th>job_type</th>\n",
              "      <th>post_date</th>\n",
              "      <th>salary_offered</th>\n",
              "      <th>state</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Trades &amp; Services</td>\n",
              "      <td>Newcastle, Maitland &amp; Hunter</td>\n",
              "      <td>The Local Bloke Lawn &amp; Garden Care</td>\n",
              "      <td>AU</td>\n",
              "      <td>seek</td>\n",
              "      <td>Newcastle Location Car License Required Previ...</td>\n",
              "      <td>Lawn &amp; Garden Care Position</td>\n",
              "      <td>Casual/Vacation</td>\n",
              "      <td>2018-04-16T01:15:22Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.seek.com.au/job/35990983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Manufacturing, Transport &amp; Logistics</td>\n",
              "      <td>Sydney</td>\n",
              "      <td>B&amp;J City Kitchen Pty Ltd</td>\n",
              "      <td>AU</td>\n",
              "      <td>seek</td>\n",
              "      <td>Beak &amp; Johnston are industry leaders within t...</td>\n",
              "      <td>Machine Operator - Food Manufacturing</td>\n",
              "      <td>Full Time</td>\n",
              "      <td>2018-04-13T03:00:07Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Parramatta &amp; Western Suburbs</td>\n",
              "      <td>https://www.seek.com.au/job/35978566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Community Services &amp; Development</td>\n",
              "      <td>Katherine &amp; Northern Australia</td>\n",
              "      <td>YMCA of the Northern Territory</td>\n",
              "      <td>AU</td>\n",
              "      <td>seek</td>\n",
              "      <td>The Opportunity Do you enjoy a challenge, lov...</td>\n",
              "      <td>Youth Diversion Worker</td>\n",
              "      <td>Full Time</td>\n",
              "      <td>2018-04-11T03:50:48Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.seek.com.au/job/35957875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Real Estate &amp; Property</td>\n",
              "      <td>Sydney</td>\n",
              "      <td>Dexus</td>\n",
              "      <td>AU</td>\n",
              "      <td>seek</td>\n",
              "      <td>Work on one of the best property portfolios i...</td>\n",
              "      <td>Communications and Investor Development Manager</td>\n",
              "      <td>Full Time</td>\n",
              "      <td>2018-04-15T23:10:56Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CBD, Inner West &amp; Eastern Suburbs</td>\n",
              "      <td>https://www.seek.com.au/job/35989342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hospitality &amp; Tourism</td>\n",
              "      <td>Cairns &amp; Far North</td>\n",
              "      <td>Hays Trades &amp; Labour</td>\n",
              "      <td>AU</td>\n",
              "      <td>seek</td>\n",
              "      <td>Permanent position on offer for a Junior Sous...</td>\n",
              "      <td>Junior Sous Chef</td>\n",
              "      <td>Full Time</td>\n",
              "      <td>2018-04-12T02:07:23Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.seek.com.au/job/35967182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>Information &amp; Communication Technology</td>\n",
              "      <td>Sydney</td>\n",
              "      <td>Hays Information Technology</td>\n",
              "      <td>AU</td>\n",
              "      <td>seek</td>\n",
              "      <td>Junior .Net Developer required for a start-up...</td>\n",
              "      <td>Junior .Net Developer</td>\n",
              "      <td>Contract/Temp</td>\n",
              "      <td>2018-04-13T06:19:44Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CBD, Inner West &amp; Eastern Suburbs</td>\n",
              "      <td>https://www.seek.com.au/job/35982781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>Trades &amp; Services</td>\n",
              "      <td>Melbourne</td>\n",
              "      <td>Zoom Recruitment &amp; Training</td>\n",
              "      <td>AU</td>\n",
              "      <td>seek</td>\n",
              "      <td>We are seeking general labourers/ hands for v...</td>\n",
              "      <td>General Labourers</td>\n",
              "      <td>Contract/Temp</td>\n",
              "      <td>2018-04-16T06:42:38Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bayside &amp; South Eastern Suburbs</td>\n",
              "      <td>https://www.seek.com.au/job/35997078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>Sales</td>\n",
              "      <td>Melbourne</td>\n",
              "      <td>Recruitmore VIC</td>\n",
              "      <td>AU</td>\n",
              "      <td>seek</td>\n",
              "      <td>No industry experience? No worries! Use your ...</td>\n",
              "      <td>IMMEDIATE STARTS - SALES &amp; CUSTOMER SERVICE</td>\n",
              "      <td>Contract/Temp</td>\n",
              "      <td>2018-04-14T23:00:07Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CBD &amp; Inner Suburbs</td>\n",
              "      <td>https://www.seek.com.au/job/35987014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>Construction</td>\n",
              "      <td>Sydney</td>\n",
              "      <td>Hays Construction</td>\n",
              "      <td>AU</td>\n",
              "      <td>seek</td>\n",
              "      <td>This large building construction firm are loo...</td>\n",
              "      <td>Senior Contract Administrator</td>\n",
              "      <td>Full Time</td>\n",
              "      <td>2018-04-16T02:44:21Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CBD, Inner West &amp; Eastern Suburbs</td>\n",
              "      <td>https://www.seek.com.au/job/35992778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>Education &amp; Training</td>\n",
              "      <td>Melbourne</td>\n",
              "      <td>anzuk Education</td>\n",
              "      <td>AU</td>\n",
              "      <td>seek</td>\n",
              "      <td>anzukÂ is an education services company, that ...</td>\n",
              "      <td>Japanese Teacher</td>\n",
              "      <td>Contract/Temp</td>\n",
              "      <td>2018-04-11T04:01:04Z</td>\n",
              "      <td>$305+ per day depending on experience</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.seek.com.au/job/35958118</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce98d964-64f1-45f1-a1b4-7ed3c212efcd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce98d964-64f1-45f1-a1b4-7ed3c212efcd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce98d964-64f1-45f1-a1b4-7ed3c212efcd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#import ftfy\n",
        "df = pd.read_csv (df_args.unprocessed_csv)\n",
        "df = df.sample(frac=df_args.frac, ignore_index=True, random_state=1) # this also shuffles the dataframe\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chGbyriMx2yY"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFPiHCf1x2ya"
      },
      "source": [
        "#### Preparing the dataframe for classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOw0YCP5x2yp"
      },
      "source": [
        "Remove unnecessary columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIvHiGqUx2yr"
      },
      "outputs": [],
      "source": [
        "features_to_delete = ['job_board','geo','url', 'city', 'post_date', 'salary_offered', 'state', \"company_name\", \"job_title\"] # get rid of unnecessary features (maybe add more columns)\n",
        "df = df.drop(features_to_delete, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV3e-47Ux2y6"
      },
      "source": [
        "Retrieve the number of null values in each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T32lnCb1x2y8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48d8f52-cb0e-4112-a547-164eda95dc22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "category             0\n",
              "job_description    345\n",
              "job_type             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsZafhtkx2y-"
      },
      "source": [
        "Job description is the feature columns and will be used for all the classification tasks, thus all rows that are missing values for the column can be dropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhdYDFVrx2zM"
      },
      "outputs": [],
      "source": [
        "df.dropna(subset=['job_description'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hIhDZD2x2zO"
      },
      "source": [
        "Decode the text in the job description column and use gensim for tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0XGQkzvx2zP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350,
          "referenced_widgets": [
            "7e31080dc04f488f8fa1750c31b91af0",
            "39f7fc65e6684bd5bf6e9adfbea1d190",
            "8219048cd699438e9dfd4bfbac686f53",
            "b9b794275bd44885ae7195ed6fc3d324",
            "ba100c1b5288414a80b85360c3924b0b",
            "6b4d4c15c6314dbc8da6afc07f748644",
            "0b9160755ad141d5b8df66dbcfe1b744",
            "7bea1e2e32f842e883de3f6c472fceae",
            "3125f975af66486f9ab98a066349c814",
            "8059e313aeb24bd18efb649d97abe6d3",
            "417f67bac06148ba8b50d28681c7cf6f"
          ]
        },
        "outputId": "2917a37c-0659-4f8c-edee-c4a80859b04f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/29655 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e31080dc04f488f8fa1750c31b91af0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-0e7cdc400436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m\"job_description\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     df.loc[i, \"job_description\"] = gensim.utils.simple_preprocess(\n\u001b[0;32m----> 3\u001b[0;31m         ftfy.fix_text(unicodedata.normalize(\"NFKD\",df.loc[i,\"job_description\"])), deacc=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ftfy/__init__.py\u001b[0m in \u001b[0;36mfix_text\u001b[0;34m(text, config, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munescape_html\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"auto\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"<\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munescape_html\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0mfixed_segment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_and_explain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ftfy/__init__.py\u001b[0m in \u001b[0;36mfix_and_explain\u001b[0;34m(text, config, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_encoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_encoding_and_explain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ftfy/__init__.py\u001b[0m in \u001b[0;36mfix_encoding\u001b[0;34m(text, config, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFixerConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_config_from_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m     \u001b[0mfixed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_explan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_encoding_and_explain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ftfy/__init__.py\u001b[0m in \u001b[0;36mfix_encoding_and_explain\u001b[0;34m(text, config, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mprevtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fix_encoding_one_step_and_explain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplan\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mplan_so_far\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ftfy/__init__.py\u001b[0m in \u001b[0;36m_fix_encoding_one_step_and_explain\u001b[0;34m(text, config)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;31m# The first plan is to return ASCII text unchanged, as well as text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;31m# that doesn't look like it contains mojibake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mchardata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpossible_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ascii\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_bad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mExplainedText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ftfy/badness.py\u001b[0m in \u001b[0;36mis_bad\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0mlonger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mhave\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhigher\u001b[0m \u001b[0mchance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mreturning\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mis_bad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \"\"\"\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBADNESS_RE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i in tqdm(df[ \"job_description\"].index):\n",
        "    df.loc[i, \"job_description\"] = gensim.utils.simple_preprocess(\n",
        "        ftfy.fix_text(unicodedata.normalize(\"NFKD\",df.loc[i,\"job_description\"])), deacc=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qoYfQGPx2zR"
      },
      "source": [
        "Create_tfidf function creates a dataframe with each row representing a document with corresponding tfidf scores and the columns showing the full corpus vocabulary. Thus the tfidf score for each word in each document can be looked up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5bxoKxyx2zc"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Allows passing tokens to the vectorizer\n",
        "def dummy_fun(doc):\n",
        "    return doc\n",
        "\n",
        "def create_tfidf_df(tokens):  \n",
        "    \"\"\"\n",
        "    Returns a bag of words data frame to fetch the tfidf score for each document\n",
        "    tokens: the corpus as a list of tokens\n",
        "    \"\"\"\n",
        "    from nltk.corpus import stopwords\n",
        "    stopwords = stopwords.words('english')\n",
        "    tfidf = TfidfVectorizer(\n",
        "    analyzer='word',\n",
        "    tokenizer=dummy_fun,\n",
        "    preprocessor=dummy_fun,\n",
        "    token_pattern=None,\n",
        "    stop_words=stopwords) \n",
        "\n",
        "    tdf = tfidf.fit_transform(tokens)\n",
        "    bow = pd.DataFrame(tdf.toarray(), columns = tfidf.get_feature_names_out())\n",
        "\n",
        "    return bow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB4AKfGUx2zi"
      },
      "source": [
        "Top x tfidf accepts a list of tokenized documents and removes all words that do not have the top x tfidf scores. Removes all words that do not have the top 10 tfidf scores. Treats each category as its own corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ3qhzz9x2zu"
      },
      "outputs": [],
      "source": [
        "df['short_description'] = [None for i in range(len(df))]\n",
        "def top_x_tfidf(df, x):\n",
        "    \"\"\"\n",
        "    df is the dataframe to modify, x represents the top x words to leave in each document. Returns a list of documents as tokens. \n",
        "    \"\"\"\n",
        "    for category in tqdm(df.category.unique()):\n",
        "        tfidf_df = create_tfidf_df(df[df.category == category]['job_description'])\n",
        "        col_names= set(tfidf_df.columns)\n",
        "        for i, (idx_row) in enumerate(df[df.category == category].iterrows()):\n",
        "            idx, row = idx_row\n",
        "            desc = row['job_description']\n",
        "            words = set(desc)        \n",
        "            if len(words) < x: \n",
        "                df.loc[idx]['short_description'] = words\n",
        "                continue\n",
        "            words = words.intersection(col_names)\n",
        "\n",
        "            # Create a dictionary of words and their tfidf values and then sort them in descending order\n",
        "            tfidf_words = {word: tfidf_df.iloc[i][word] for word in words}\n",
        "            tfidf_words = {k: v for k, v in sorted(tfidf_words.items(), key=lambda item: -item[1])}\n",
        "\n",
        "            for word in desc:\n",
        "                if word not in list(tfidf_words.keys())[:x]: # Remove all words who are not in the top ten tfidf scores\n",
        "                    desc = list(filter(lambda x: x != word, desc))\n",
        "            df.loc[idx]['short_description'] = desc\n",
        "    return df['short_description']\n",
        "df['short_description'] = top_x_tfidf(df, 10)\n",
        "df['short_description']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['short_description']"
      ],
      "metadata": {
        "id": "OBPh-clHQopJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO_YDaWFx2zy"
      },
      "source": [
        "Prepare the job type column for binary classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX9QYHrJx2zz"
      },
      "outputs": [],
      "source": [
        "df.rename(columns = {'job_type': 'job_type_target'}, inplace=True) # Specify the target column\n",
        "df.loc[df['job_type_target'] != 'Full Time', 'job_type_target'] = 'Other'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTR-i30Fx2z0"
      },
      "source": [
        "Observe the distribution of classes in the target column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EfA1W0Yx2z1"
      },
      "outputs": [],
      "source": [
        "df['job_type_target'].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvyDeJhXx20D"
      },
      "outputs": [],
      "source": [
        "df['job_type_target'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZBjcvJFx20E"
      },
      "source": [
        "Now we can define the baseline accuracy for the models as below: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6k-iWwRx20F"
      },
      "outputs": [],
      "source": [
        "1970/len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzGt7eVvx20G"
      },
      "source": [
        "Now split the data frame into train, test and validation then write the dataframe into a csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WihHJJUBx20H"
      },
      "outputs": [],
      "source": [
        "n = len(df)\n",
        "n_train = int(df_args.train_proportion*n)\n",
        "n_val = int(df_args.val_proportion*n)\n",
        "n_test = int(df_args.test_proportion*n)\n",
        "\n",
        "df['split'] = ['nil' for i in range(len(df))]\n",
        "\n",
        "for idx, _ in df[:n_train].iterrows():\n",
        "    df.loc[idx]['split'] = 'train'\n",
        "for idx, _ in df[n_train:n_train+n_val].iterrows():\n",
        "    df.loc[idx]['split'] = 'val'\n",
        "for idx, _ in df[n_train+n_val:].iterrows():\n",
        "    df.loc[idx]['split'] = 'test' \n",
        "df['split'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b9jJmvyx20V"
      },
      "outputs": [],
      "source": [
        "df.job_description = df.job_description.apply(lambda x: ' '.join(x))\n",
        "df.short_description = df.short_description.apply(lambda x: ' '.join(x)) # lists cannot be stored in csv\n",
        "df.to_csv(df_args.processed_csv, index=False)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qNCL3ivx20r"
      },
      "source": [
        "Load the dataframe if already saved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8UqTTUzx20r"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(df_args.processed_csv)\n",
        "df.short_description = df.short_description.apply(lambda x: x.split(' '))\n",
        "df.job_description = df.job_description.apply(lambda x: x.split(' '))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoX7-judx208"
      },
      "source": [
        "## Creating word vectors to be used when training the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyeVs640x209"
      },
      "outputs": [],
      "source": [
        "vectorizer_args = Namespace(\n",
        "    load_word2vec = True,\n",
        "    word2vec_model_filepath = os.path.join(script_dir, 'model_storage/word2vec'),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y856jxqBx21L"
      },
      "source": [
        "#### Loading the pretrained glove model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_EY2-55x21M"
      },
      "outputs": [],
      "source": [
        "def load_embedding_model():\n",
        "    \"\"\" Load GloVe Vectors\n",
        "        Return:\n",
        "            wv_from_bin: All 400000 embeddings, each lengh 200\n",
        "    \"\"\"\n",
        "    import gensim.downloader as api\n",
        "    wv_pretrained = api.load(\"glove-wiki-gigaword-100\")\n",
        "    #print(\"Loaded vocab size %i\" % len(wv_pretrained.key_to_index))\n",
        "    print(\"The loaded object is of type %s\" % str(type(wv_pretrained)))\n",
        "    return wv_pretrained\n",
        "glove_model = load_embedding_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wmw9OAux21e"
      },
      "source": [
        "### Word embedding visualization with tsne and word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJVYv4Pfx21f"
      },
      "source": [
        "First train or load a domain specific word2vec model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh9cnPNjx21f"
      },
      "outputs": [],
      "source": [
        "if vectorizer_args.load_word2vec:\n",
        "    word2vec_model = Word2Vec.load(vectorizer_args.word2vec_model_filepath).wv # Model may not load on different OS so change vector_args\n",
        "\n",
        "else:\n",
        "    # Configuration was taken from labs\n",
        "    word2vec = Word2Vec(min_count=1,\n",
        "                        window=2, # We are trying to find \"Full time\"\n",
        "                        size=100,\n",
        "                        sample=6e-5, \n",
        "                        alpha=0.03, \n",
        "                        min_alpha=0.0007, \n",
        "                        negative=20,\n",
        "                        workers=15)\n",
        "    t = time()\n",
        "\n",
        "    word2vec.build_vocab(df['job_description'], progress_per=10)\n",
        "\n",
        "    print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))\n",
        "    t = time()\n",
        "\n",
        "    word2vec.train(df['job_description'], total_examples=word2vec.corpus_count, epochs=10, report_delay=1)\n",
        "    word2vec_model = word2vec.wv\n",
        "    word2vec_model.wv.save(vectorizer_args.word2vec_model_filepath)\n",
        "    print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "688kvyfkx21h"
      },
      "source": [
        "Define some functions to help with plotting the words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ECq_UlEx21h"
      },
      "outputs": [],
      "source": [
        "def interactive_tsne(text_labels, tsne_array):\n",
        "    '''makes an interactive scatter plot with text labels for each point'''\n",
        "\n",
        "    # Define a dataframe to be used by bokeh context\n",
        "    bokeh_df = pd.DataFrame(tsne_array, text_labels, columns=['x','y'])\n",
        "    bokeh_df['text_labels'] = bokeh_df.index\n",
        "\n",
        "    # interactive controls to include to the plot\n",
        "    TOOLS=\"hover, zoom_in, zoom_out, box_zoom, undo, redo, reset, box_select\"\n",
        "\n",
        "    p = figure(tools=TOOLS, plot_width=700, plot_height=700)\n",
        "\n",
        "    # define data source for the plot\n",
        "    source = ColumnDataSource(bokeh_df)\n",
        "\n",
        "    # scatter plot\n",
        "    p.scatter('x', 'y', source=source, fill_alpha=0.6,\n",
        "              fill_color=\"#8724B5\",\n",
        "              line_color=None)\n",
        "\n",
        "    # text labels\n",
        "    labels = LabelSet(x='x', y='y', text='text_labels', y_offset=8,\n",
        "                      text_font_size=\"8pt\", text_color=\"#555555\",\n",
        "                      source=source, text_align='center')\n",
        "\n",
        "    p.add_layout(labels)\n",
        "\n",
        "    # show plot inline\n",
        "    output_notebook()\n",
        "    show(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jC9tVAkMx21x"
      },
      "outputs": [],
      "source": [
        "def display_closestwords_tsnescatterplot(model, word, vec_length):\n",
        "    \n",
        "    arr = np.empty((0,vec_length), dtype='f')\n",
        "    word_labels = [word]\n",
        "\n",
        "    # get close words\n",
        "    close_words = model.similar_by_word(word)\n",
        "    \n",
        "    # add the vector for each of the closest words to the array\n",
        "    arr = np.append(arr, np.array([model[word]]), axis=0)\n",
        "    for wrd_score in close_words:\n",
        "        wrd_vector = model[wrd_score[0]]\n",
        "        word_labels.append(wrd_score[0])\n",
        "        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
        "        \n",
        "    # find tsne coords for 2 dimensions\n",
        "    tsne = TSNE(n_components=2, random_state=0)\n",
        "    np.set_printoptions(suppress=True)\n",
        "    Y = tsne.fit_transform(arr)\n",
        "\n",
        "    x_coords = Y[:, 0]\n",
        "    y_coords = Y[:, 1]\n",
        "    # display scatter plot\n",
        "    plt.scatter(x_coords, y_coords)\n",
        "\n",
        "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
        "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
        "    plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005)\n",
        "    plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005)\n",
        "    plt.title(f'Words closest to: {word}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5lvYmaXx21z"
      },
      "source": [
        "Below plot shows the distribution of some example words of the domain specific word2vec that was trained previously"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmVytsfex210"
      },
      "outputs": [],
      "source": [
        "vocab  = word2vec_model.index2word[:100]\n",
        "random.shuffle(vocab)\n",
        "vocab = [word for word in vocab if word not in stopwords]\n",
        "X = word2vec_model[vocab]\n",
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "X_tsne = tsne.fit_transform(X)\n",
        "interactive_tsne(list(vocab), X_tsne)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rroiRa2Mx22C"
      },
      "source": [
        "Now plot the same words but on the pretrained glove model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7anMyWex22F"
      },
      "outputs": [],
      "source": [
        "vocab = [word for word in vocab if word in glove_model.index2word]\n",
        "X = glove_model[vocab]\n",
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "X_tsne = tsne.fit_transform(X)\n",
        "interactive_tsne(list(vocab), X_tsne)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf-tWZNWx22W"
      },
      "source": [
        "#### Closest words comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBA_u0yHx22X"
      },
      "source": [
        "A better indication for the differences between the two embedding models would be a plot of a common word with their closest neighbours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AibIkfdvx22X"
      },
      "outputs": [],
      "source": [
        "display_closestwords_tsnescatterplot(glove_model, 'fifo', 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vj9jXR4Wx22Z"
      },
      "outputs": [],
      "source": [
        "display_closestwords_tsnescatterplot(word2vec_model.wv, 'fifo', 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRSSciwXx226"
      },
      "source": [
        "The above plots better communicate how the closest words are highly dependent on the source of the dataset that the embeddings were derived from. For example perth is a close word to fifo in the word2vec model but not in the pretrained glove model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing some helper classes"
      ],
      "metadata": {
        "id": "zM2m72bJL-6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below clases are used in the implementaiton of the neural networks in the next section. "
      ],
      "metadata": {
        "id": "_rpR9eEQODaV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wefytaipx23O"
      },
      "outputs": [],
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\"Class to process text and extract Vocabulary for mapping\"\"\"\n",
        "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            token_to_idx (dict): a pre-existingmap of tokens to indices\n",
        "            add_unk (bool): a flag that indicates whether to add the UNK token\n",
        "            unk_token (str): the UNK token to add into the Vocabulary\n",
        "        \"\"\"\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self._token_to_idx = token_to_idx\n",
        "        self._idx_to_token = {idx: token \n",
        "                                for token, idx in self._token_to_idx.items()}\n",
        "        self._add_unk = add_unk\n",
        "        self._unk_token = unk_token\n",
        "        self.unk_index = 1\n",
        "        if add_unk:\n",
        "            self.unk_index = self.add_token(unk_token)\n",
        "    def to_serializable(self):\n",
        "        \"\"\" returns a dictionary that can be serialized \"\"\"\n",
        "        return {'token_to_idx': self._token_to_idx,\n",
        "                'add_unk': self._add_unk,\n",
        "                'unk_token': self._unk_token}\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
        "        return cls(**contents)\n",
        "    def add_token(self, token):\n",
        "        \"\"\"Update mapping dicts based on the token.\n",
        "        Args:\n",
        "            token (str): the item to add into the Vocabulary\n",
        "        Returns:\n",
        "            index (int): the integer corresponding to the token\n",
        "        \"\"\"\n",
        "        if token in self._token_to_idx:\n",
        "            index = self._token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "    \n",
        "    def add_many(self, tokens):\n",
        "        \"\"\"Add a list of tokens into the Vocabulary\n",
        "        \n",
        "        Args:\n",
        "            tokens (list): a list of string tokens\n",
        "        Returns:\n",
        "            indices (list): a list of indices corresponding to the tokens\n",
        "        \"\"\"\n",
        "        return [self.add_token(token) for token in tokens]\n",
        "    \n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"Retrieve the index associated with the token\n",
        "        or the UNK index if token isn't present.\n",
        "        Args:\n",
        "            token (str): the token to look up\n",
        "        Returns:\n",
        "            index (int): the index corresponding to the token\n",
        "        Notes:\n",
        "            `unk_index` needs to be >=0 (having been added into the Vocabulary)\n",
        "            for the UNK functionality\n",
        "        \"\"\"\n",
        "        if self._add_unk:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]\n",
        "    def lookup_index(self, index):\n",
        "        \"\"\"Return the token associated with the index\n",
        "        Args:\n",
        "            index (int): the index to look up\n",
        "        Returns:\n",
        "            token (str): the token corresponding to the index\n",
        "        Raises:\n",
        "        KeyError: if the index is not in the Vocabulary\n",
        "        \"\"\"\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6j6xuRdx23c"
      },
      "outputs": [],
      "source": [
        "class One_hot_Vectorizer(object):\n",
        "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
        "    def __init__(self, description_vocab, target_vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            description_vocab (Vocabulary): maps words to integers\n",
        "            target_vocab (Vocabulary): maps class labels to integers\n",
        "        \"\"\"\n",
        "        self.description_vocab = description_vocab\n",
        "        self.target_vocab = target_vocab\n",
        "    def vectorize(self, description_tokenized):\n",
        "        \"\"\"Create a collapsed one hot vector for the job description\n",
        "        Args:\n",
        "            description_tokenized (list): the tokenized job description\n",
        "        Returns:\n",
        "            one_hot (np.ndarray): the collapsed onehot encoding\n",
        "        \"\"\"\n",
        "        one_hot = np.zeros(len(self.description_vocab), dtype=np.float32)\n",
        "        for token in description_tokenized:\n",
        "            if token not in string.punctuation:\n",
        "                one_hot[self.description_vocab.lookup_token(token)] = 1\n",
        "        return one_hot\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, description_df, target_cat = True, cutoff=25):\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
        "        Args:\n",
        "            description_df (pandas.DataFrame): the description dataset\n",
        "            cutoff (int): the parameter for frequency based filtering\n",
        "        Returns:\n",
        "            an instance of the descriptionVectorizer\n",
        "        \"\"\"\n",
        "        description_vocab = Vocabulary(add_unk=True)\n",
        "        target_vocab = Vocabulary(add_unk=False)\n",
        "        # adding category or Job_type\n",
        "        if target_cat:\n",
        "            for category in sorted(set(description_df.category)):\n",
        "                target_vocab.add_token(category)\n",
        "        \n",
        "        else:\n",
        "            \n",
        "            for job_type in  sorted(set(description_df.job_type_target)):\n",
        "                target_vocab.add_token(job_type)\n",
        "        # Add top words if count > provided count\n",
        "        word_counts = Counter()\n",
        "        for description in description_df.job_description:\n",
        "            for word in description:\n",
        "                if word not in string.punctuation:\n",
        "                    word_counts[word] += 1\n",
        "        for word, count in word_counts.items():\n",
        "            if count > cutoff:\n",
        "                description_vocab.add_token(word)\n",
        "        return cls(description_vocab, target_vocab)\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\"Intantiate a descriptionVectorizer from a serializable dictionary\n",
        "        Args:\n",
        "            contents (dict): the serializable dictionary\n",
        "        Returns:\n",
        "            an instance of the descriptionVectorizer class\n",
        "        \"\"\"\n",
        "        description_vocab = Vocabulary.from_serializable(contents['description_vocab'])\n",
        "        target_vocab = Vocabulary.from_serializable(contents['target_vocab'])\n",
        "        return cls(description_vocab=description_vocab, target_vocab=target_vocab)\n",
        "    def to_serializable(self):\n",
        "        \"\"\"Create the serializable dictionary for caching\n",
        "        Returns:\n",
        "            contents (dict): the serializable dictionary\n",
        "        \"\"\"\n",
        "        return {'description_vocab': self.description_vocab.to_serializable(),\n",
        "                'target_vocab': self.target_vocab.to_serializable()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd7E8CHLx23i"
      },
      "outputs": [],
      "source": [
        "class SequenceVocabulary(Vocabulary):\n",
        "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
        "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
        "                 end_seq_token=\"<END>\"):\n",
        "\n",
        "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
        "\n",
        "        self._mask_token = mask_token\n",
        "        self._unk_token = unk_token\n",
        "        self._begin_seq_token = begin_seq_token\n",
        "        self._end_seq_token = end_seq_token\n",
        "\n",
        "        self.mask_index = self.add_token(self._mask_token)\n",
        "        self.unk_index = self.add_token(self._unk_token)\n",
        "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
        "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        contents = super(SequenceVocabulary, self).to_serializable()\n",
        "        contents.update({'unk_token': self._unk_token,\n",
        "                         'mask_token': self._mask_token,\n",
        "                         'begin_seq_token': self._begin_seq_token,\n",
        "                         'end_seq_token': self._end_seq_token})\n",
        "        return contents\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"Retrieve the index associated with the token \n",
        "          or the UNK index if token isn't present.\n",
        "        \n",
        "        Args:\n",
        "            token (str): the token to look up \n",
        "        Returns:\n",
        "            index (int): the index corresponding to the token\n",
        "        Notes:\n",
        "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
        "              for the UNK functionality \n",
        "        \"\"\"\n",
        "        if self.unk_index >= 0:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZf0oi2hx239"
      },
      "outputs": [],
      "source": [
        "class Vectorizer(object):\n",
        "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"    \n",
        "    def __init__(self, desc_vocab, target_vocab):\n",
        "        self.description_vocab = desc_vocab\n",
        "        self.target_vocab = target_vocab\n",
        "    def vectorize(self, description, vector_length=-1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            description (list) : tokenized description \n",
        "            vector_length (int): an argument for forcing the length of index vector\n",
        "        Returns:\n",
        "            the vetorized description (numpy.array)\n",
        "        \"\"\"\n",
        "        indices = []\n",
        "        \n",
        "        \n",
        "        indices.extend(self.description_vocab.lookup_token(token) \n",
        "                       for token in description)\n",
        "        if vector_length < 0:\n",
        "            vector_length = len(indices)\n",
        "        \n",
        "        out_vector = np.zeros(vector_length, dtype=np.int64)\n",
        "     \n",
        "        out_vector[:len(indices)] = indices\n",
        "       \n",
        "\n",
        "        return out_vector\n",
        "      \n",
        "    def vectorize_one_hot(self, description):\n",
        "        \"\"\"Create a collapsed one hot vector for the job description\n",
        "        Args:\n",
        "            description_tokenized (list): the tokenized job description\n",
        "        Returns:\n",
        "            one_hot (np.ndarray): the collapsed onehot encoding\n",
        "        \"\"\"\n",
        "        one_hot = np.zeros(len(self.description_vocab), dtype=np.float32)\n",
        "        for token in description:\n",
        "            if token not in string.punctuation:\n",
        "                one_hot[self.description_vocab.lookup_token(token)] = 1\n",
        "        return one_hot\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, df, feature_column = 'short_description', target_cat = False, cutoff=10):\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
        "        Args:\n",
        "            description_df (pandas.DataFrame): the target dataset\n",
        "            cutoff (int): frequency threshold for including in Vocabulary \n",
        "        Returns:\n",
        "            an instance of the descriptionVectorizer\n",
        "        \"\"\"\n",
        "        target_vocab = Vocabulary(add_unk=False)\n",
        "        if target_cat:\n",
        "            for target in sorted(set(df.category)):\n",
        "                target_vocab.add_token(target)    \n",
        "        else:\n",
        "            for job_type in sorted(set(df.job_type_target)):\n",
        "                target_vocab.add_token(job_type)\n",
        "        \n",
        " \n",
        "        word_counts = Counter()\n",
        "        for desc in df[feature_column]:\n",
        "            desc = desc.split(' ') if type(desc) is not list else desc\n",
        "            for token in desc:\n",
        "                word_counts[token] += 1\n",
        "\n",
        "        desc_vocab = SequenceVocabulary()\n",
        "        for word, word_count in word_counts.items():\n",
        "            if word_count >= cutoff:\n",
        "                desc_vocab.add_token(word)\n",
        "        \n",
        "        return cls(desc_vocab, target_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        description_vocab = \\\n",
        "            SequenceVocabulary.from_serializable(contents['description_vocab'])\n",
        "        target_vocab =  \\\n",
        "            Vocabulary.from_serializable(contents['target_vocab'])\n",
        "\n",
        "        return cls(description_vocab=description_vocab, target_vocab=target_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'description_vocab': self.description_vocab.to_serializable(),\n",
        "                'target_vocab': self.target_vocab.to_serializable()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ugo1tPU6x24A"
      },
      "outputs": [],
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, df, vectorizer, short = True, job_type = True, one_hot= False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df (pandas.DataFrame): the dataset\n",
        "            vectorizer (GloveVectorizer): vectorizer instatiated from dataset\n",
        "        \"\"\"\n",
        "        self.one_hot = one_hot\n",
        "        self.df = df\n",
        "        self._vectorizer = vectorizer\n",
        "        self.short = short\n",
        "        self.job_type = job_type\n",
        "\n",
        "        # +1 if only using begin_seq, +2 if using both begin and end seq tokens\n",
        "        measure_len = lambda context: len(context)\n",
        "        if self.short:\n",
        "            self._max_seq_length = max(map(measure_len, df.short_description)) + 2\n",
        "        else:\n",
        "            self._max_seq_length = max(map(measure_len, df.job_description)) + 2\n",
        "        \n",
        "        self.train_df = self.df[self.df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.df[self.df.split=='val']\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.df[self.df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
        "                             'val': (self.val_df, self.validation_size),\n",
        "                             'test': (self.test_df, self.test_size)}\n",
        "\n",
        "        self.set_split('train')\n",
        "\n",
        "        # Class weights\n",
        "        if self.job_type:\n",
        "            class_counts = df.job_type_target.value_counts().to_dict()\n",
        "        else:\n",
        "            class_counts = df.category.value_counts().to_dict()\n",
        "        def sort_key(item):\n",
        "            return self._vectorizer.target_vocab.lookup_token(item[0])\n",
        "        \n",
        "\n",
        "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
        "        frequencies = [count for _, count in sorted_counts]\n",
        "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
        "        \n",
        "        \n",
        "    @classmethod\n",
        "    def load_df_and_make_vectorizer(cls, df, short = True, job_type = True):\n",
        "        \"\"\"Load dataset and make a  vectorizer from scratch\n",
        "        \n",
        "        Args:\n",
        "            csv (str): location of the dataset\n",
        "        Returns:\n",
        "            an instance of Dataset\n",
        "        \"\"\"\n",
        "        train_df = df[df.split=='train']\n",
        "        return cls(df, Vectorizer.from_dataframe(train_df), short = short)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        \"\"\"a static method for loading the vectorizer from file\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
        "        Returns:\n",
        "            an instance of GloveVectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return Vectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        \"\"\"saves the vectorizer to disk using json\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location to save the vectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\" returns the vectorizer \"\"\"\n",
        "        return self._vectorizer\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"the primary entry point method for PyTorch datasets\n",
        "        \n",
        "        Args:\n",
        "            index (int): the index to the data point \n",
        "        Returns:\n",
        "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
        "        \"\"\"\n",
        "        row = self._target_df.iloc[index]\n",
        "\n",
        "        if self.one_hot:\n",
        "            if self.short:\n",
        "                description_vector = \\\n",
        "                    self._vectorizer.vectorize_one_hot(row.short_description)\n",
        "            else:\n",
        "                description_vector = \\\n",
        "                    self._vectorizer.vectorize_one_hot(row.job_description)\n",
        "\n",
        "        else:\n",
        "            if self.short:\n",
        "                description_vector = \\\n",
        "                    self._vectorizer.vectorize(row.short_description, self._max_seq_length)\n",
        "            else:\n",
        "                description_vector = \\\n",
        "                    self._vectorizer.vectorize(row.job_description, self._max_seq_length)\n",
        "\n",
        "        if self.job_type:\n",
        "            target_index = \\\n",
        "                self._vectorizer.target_vocab.lookup_token(row.job_type_target)\n",
        "        else:\n",
        "            target_index = \\\n",
        "                self._vectorizer.target_vocab.lookup_token(row.category)\n",
        "\n",
        "\n",
        "        return {'x_data': description_vector,\n",
        "                'y_target': target_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
        "        \n",
        "        Args:\n",
        "            batch_size (int)\n",
        "        Returns:\n",
        "            number of batches in the dataset\n",
        "        \"\"\" \n",
        "        return len(self) // batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UH3z-aLx23g"
      },
      "source": [
        "## Comparing neural network models on binary and multiclass classification tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJF-WoSsx23i"
      },
      "source": [
        "Define some classes to help train the classification model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uApVi-Mx24D"
      },
      "source": [
        "### Defining some helper functions for training each model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnWxjUakx24S"
      },
      "outputs": [],
      "source": [
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=True, device=\"cpu\"): \n",
        "    \"\"\"\n",
        "    A generator function which wraps the PyTorch DataLoader. It will \n",
        "      ensure each tensor is on the write device location.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        for name, tensor in data_dict.items():\n",
        "            out_data_dict[name] = data_dict[name].to(device)\n",
        "        yield out_data_dict\n",
        "\n",
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 4,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}\n",
        "\n",
        "def update_train_state(args, model, train_state):\n",
        "    \"\"\"Handle the training state updates.\n",
        "\n",
        "    Components:\n",
        "     - Early Stopping: Prevent overfitting.\n",
        "     - Model Checkpoint: Model is saved if the model is better\n",
        "\n",
        "    :param args: main arguments\n",
        "    :param model: model to train\n",
        "    :param train_state: a dictionary representing the training state values\n",
        "    :returns:\n",
        "        a new train_state\n",
        "    \"\"\"\n",
        "\n",
        "    # Save one model at least\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # Save model if performance improved\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "\n",
        "        # If loss worsened\n",
        "        if loss_t >= train_state['early_stopping_best_val']:\n",
        "            # Update step\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # Loss decreased\n",
        "        else:\n",
        "            # Save the best model\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "\n",
        "            # Reset early stopping step\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # Stop early ?\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state\n",
        "\n",
        "def compute_accuracy_binary(y_pred, y_target):\n",
        "    y_pred_indices = (torch.sigmoid(y_pred)>0.5).cpu().long().to(cnn_args.device) #.max(dim=1)[1]\n",
        "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "    return n_correct / len(y_pred_indices) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuXaIsXOx24T"
      },
      "source": [
        "The make embedding function uses a word to index dictionary for creating the embedding matrix which can be passed to the classifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_one_hot_matrix(one_hot_vectorizer, words):\n",
        "    \"\"\"\n",
        "    Args: \n",
        "        one_hot_vectorizer: of class one_hot_vectorizer \n",
        "        words: List of words in the dataset\n",
        "    Returns:\n",
        "        A matrix of the embeddings for each word matching the word's index\n",
        "    \"\"\"\n",
        "    embedding_size = len(words)\n",
        "    final_embeddings = np.zeros((len(words), len(words)))\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "      final_embeddings[i, :] = one_hot_vectorizer.vectorize(word)\n",
        "    return final_embeddings"
      ],
      "metadata": {
        "id": "w_4XPgVRh54a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1c9FPrcx24V"
      },
      "outputs": [],
      "source": [
        "def make_embedding_matrix(embeddings, word_to_idx, words):\n",
        "    \"\"\"\n",
        "    Create embedding matrix for a specific set of words.\n",
        "    \n",
        "    Args:\n",
        "        glove_filepath (str): file path to the glove embeddigns\n",
        "        words (list): list of words in the dataseta\n",
        "    \"\"\"\n",
        "    embedding_size = embeddings.shape[1]\n",
        "    \n",
        "    final_embeddings = np.zeros((len(words), embedding_size))\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        if word in word_to_idx:\n",
        "            final_embeddings[i, :] = embeddings[word_to_idx[word]]\n",
        "        else:\n",
        "            embedding_i = torch.ones(1, embedding_size)\n",
        "            torch.nn.init.xavier_uniform_(embedding_i)\n",
        "            final_embeddings[i, :] = embedding_i\n",
        "\n",
        "    return final_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U85F_CP3x24l"
      },
      "outputs": [],
      "source": [
        "def train_model(classifier, dataset, loss_func):\n",
        "  \"\"\"\n",
        "  args:\n",
        "    classifier: the pytorch model that will be trained.\n",
        "    dataset: An object from the dataset class\n",
        "  returns:\n",
        "    the classifier and the final trainstate\n",
        "  \"\"\"\n",
        "  classifier = classifier.to(cnn_args.device)\n",
        "  dataset.class_weights = dataset_short_desc.class_weights.to(cnn_args.device)\n",
        "\n",
        "  optimizer = optim.Adam(classifier.parameters(), lr = cnn_args.learning_rate)\n",
        "  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode = 'min', factor=0.5, patience=1)\n",
        "\n",
        "  train_state = make_train_state(cnn_args)\n",
        "\n",
        "  epoch_bar = tqdm(desc='training routine', \n",
        "                            total=cnn_args.num_epochs,\n",
        "                            position=0)\n",
        "\n",
        "  dataset.set_split('train')\n",
        "  train_bar = tqdm(desc='split=train',\n",
        "                            total=dataset.get_num_batches(cnn_args.batch_size), \n",
        "                            position=1, \n",
        "                            leave=True)\n",
        "  dataset.set_split('val')\n",
        "  val_bar = tqdm(desc='split=val',\n",
        "                          total=dataset.get_num_batches(cnn_args.batch_size), \n",
        "                          position=1, \n",
        "                          leave=True)\n",
        "\n",
        "\n",
        "  classifier.float() # sets classifier to receive in double precision format\n",
        "  try: \n",
        "      for epoch in range(cnn_args.num_epochs):\n",
        "          train_state['epoch_index'] = epoch\n",
        "          dataset.set_split('train')\n",
        "          batch_generator = generate_batches(dataset, batch_size=cnn_args.batch_size, device=cnn_args.device)\n",
        "\n",
        "          running_loss = 0.0\n",
        "          running_acc = 0.0\n",
        "          classifier.train()\n",
        "\n",
        "          for batch_index, batch_dict in enumerate(batch_generator):\n",
        "              optimizer.zero_grad()\n",
        "              y_pred = classifier(batch_dict['x_data'])\n",
        "  \n",
        "              loss = loss_func(y_pred.float(), batch_dict['y_target'].float())\n",
        "              loss_t = loss.item()\n",
        "              running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              acc_t = compute_accuracy_binary(y_pred, batch_dict['y_target'].to(cnn_args.device))\n",
        "              running_acc += (acc_t  - running_acc)/(batch_index+1)\n",
        "              #update bar\n",
        "              train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                                      epoch=epoch)\n",
        "              train_bar.update()\n",
        "\n",
        "          train_state['train_loss'].append(running_loss)\n",
        "          train_state['train_acc'].append(running_acc)\n",
        "\n",
        "          dataset.set_split('val')\n",
        "          batch_generator = generate_batches(dataset, batch_size=cnn_args.batch_size, device=cnn_args.device)\n",
        "          running_loss = 0.\n",
        "          running_acc = 0.\n",
        "          classifier.eval()\n",
        "\n",
        "          for batch_index, batch_dict in enumerate(batch_generator):\n",
        "              y_pred = classifier(batch_dict['x_data'])\n",
        "              loss = loss_func(y_pred.float(), batch_dict['y_target'].float())\n",
        "              loss_t = loss.item()\n",
        "              running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "              acc_t = compute_accuracy_binary(y_pred, batch_dict['y_target'])\n",
        "              running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "              val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                                  epoch=epoch)\n",
        "              val_bar.update()\n",
        "          train_state['val_loss'].append(running_loss)\n",
        "          train_state['val_acc'].append(running_acc)\n",
        "\n",
        "          train_state = update_train_state(args=cnn_args, model=classifier,\n",
        "                                          train_state=train_state)\n",
        "\n",
        "          scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "          if train_state['stop_early']:\n",
        "              break\n",
        "          train_bar.n = 0\n",
        "          val_bar.n = 0\n",
        "          epoch_bar.update()\n",
        "\n",
        "\n",
        "  except KeyboardInterrupt:\n",
        "      print(\"Exiting loop\")\n",
        "  return classifier, train_state\n",
        "\n",
        "def test_model( classifier, dataset, train_state, args,\n",
        "               loss_func, BCE=False):\n",
        "    dataset.set_split('test')\n",
        "    batch_generator = generate_batches(dataset, \n",
        "                                       batch_size=args.batch_size, \n",
        "                                       device=args.device)\n",
        "    running_loss = 0.\n",
        "    running_acc = 0.\n",
        "    classifier.eval()\n",
        "\n",
        "    for batch_index, batch_dict in enumerate(batch_generator):\n",
        "        # compute the output\n",
        "        y_pred =  classifier(batch_dict['x_data'])\n",
        "\n",
        "        # compute the loss\n",
        "        if BCE:\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
        "        else:\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "        loss_t = loss.item()\n",
        "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "    # compute the accuracy\n",
        "        if BCE:\n",
        "            acc_t = compute_accuracy_BCE(y_pred, batch_dict['y_target'])\n",
        "        else:\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "    train_state['test_loss'] = running_loss\n",
        "    train_state['test_acc'] = running_acc\n",
        "    print(\"Test loss: {};\".format(train_state['test_loss']))\n",
        "    print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmRL4NX8x24W"
      },
      "source": [
        "### CNN for Binary classification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here some global arguments are defined to be used while training the cnn model. The cnn architecture was borrowed from lab 9 and was repurposed for binary classification."
      ],
      "metadata": {
        "id": "9sHzs89jZxYp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6qxDkipx24W"
      },
      "outputs": [],
      "source": [
        "cnn_args = Namespace(\n",
        "    num_epochs=100, \n",
        "    early_stopping_criteria=5,\n",
        "    learning_rate=0.001, \n",
        "    dropout_p=0.5, \n",
        "    batch_size=50, \n",
        "    cuda=True, \n",
        "    catch_keyboard_interrupt=True, \n",
        "    reload_from_files=False,\n",
        "    expand_filepaths_to_save_dir=True,\n",
        "    save_dir=os.path.join(script_dir, \"model_storage/cnn\"),\n",
        "    model_state_file=\"cnn_model.pth\",\n",
        "    embedding_size = 100,\n",
        "    num_channels = 50,\n",
        "    hidden_dim = 200,\n",
        ")\n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    cnn_args.cuda = False\n",
        "    \n",
        "cnn_args.device = torch.device(\"cuda\" if cnn_args.cuda else \"cpu\")\n",
        "print(\"Using CUDA: {}\".format(cnn_args.cuda))\n",
        "if cnn_args.expand_filepaths_to_save_dir:\n",
        "\n",
        "    cnn_args.model_state_file = os.path.join(cnn_args.save_dir,\n",
        "                                         cnn_args.model_state_file)\n",
        "    \n",
        "    print(\"Expanded filepaths: \")\n",
        "    print(\"\\t{}\".format(cnn_args.model_state_file))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Dl2X4Mbx24X"
      },
      "source": [
        "Defining the CNN classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9glAR8uxx24X"
      },
      "outputs": [],
      "source": [
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, embedding_size, num_embeddings, num_channels, hidden_dim,\n",
        "     dropout_p, pretrained_embeddings = None, padding_idx = 0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            embedding_size (int): size of the embedding vectors\n",
        "            num_embeddings (int): number of embedding vectors\n",
        "            filter_width (int): width of the convolutional kernels\n",
        "            num_channels (int): number of convolutional kernels per layer\n",
        "            hidden_dim (int): the size of the hidden dimension\n",
        "            num_classes (int): the number of classes in classification\n",
        "            dropout_p (float): a dropout parameter \n",
        "            pretrained_embeddings (numpy.array): previously trained word embeddings\n",
        "                default is None. If provided, \n",
        "            padding_idx (int): an index representing a null position\n",
        "        \"\"\"\n",
        "        super(CNNClassifier, self).__init__()\n",
        "\n",
        "        if pretrained_embeddings is None:\n",
        "            self.emb = nn.Embedding(embedding_dim = embedding_size, num_embeddings=num_embeddings, padding_idx=padding_idx)\n",
        "        else:\n",
        "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings)\n",
        "            self.emb = nn.Embedding(embedding_dim=embedding_size,\n",
        "                                    num_embeddings=num_embeddings,\n",
        "                                    padding_idx=padding_idx,\n",
        "                                    _weight=pretrained_embeddings)\n",
        "            \n",
        "        self.convnet = nn.Sequential(nn.Conv1d(in_channels=embedding_size, \n",
        "                   out_channels=num_channels, kernel_size=3),\n",
        "                   nn.ELU(),\n",
        "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels, \n",
        "                   kernel_size=3, stride=1),\n",
        "                  nn.ELU(),\n",
        "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels, \n",
        "                   kernel_size=3, stride=2),\n",
        "            nn.ELU())\n",
        "        self._dropout_p = dropout_p\n",
        "        self.fc1 = nn.Linear(num_channels, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, out_features = 1)\n",
        "    def forward(self, x_in, apply_sigmoid=False):\n",
        "        \"\"\"The forward pass of the classifier\n",
        "        \n",
        "        Args:\n",
        "            x_in (torch.Tensor): an input data tensor. \n",
        "                x_in.shape should be (batch, dataset._max_seq_length)\n",
        "            apply_sigmoid (bool): a flag for the sigmoid activation\n",
        "                should be false if used with the Cross Entropy losses\n",
        "        Returns:\n",
        "            the resulting tensor. tensor.shape should be (batch, num_classes)\n",
        "        \"\"\"\n",
        "        \n",
        "        # embed and permute so features are channels\n",
        "        x_embedded = self.emb(x_in).permute(0, 2, 1)\n",
        "\n",
        "        features = self.convnet(x_embedded)\n",
        "\n",
        "        # average and remove the extra dimension\n",
        "        remaining_size = features.size(dim=2)\n",
        "    \n",
        "        features = F.avg_pool1d(features, remaining_size).squeeze(dim=2)\n",
        "        features = F.dropout(features, p=self._dropout_p)\n",
        "        \n",
        "        # mlp classifier\n",
        "        intermediate_vector = F.relu(F.dropout(self.fc1(features), p=self._dropout_p))\n",
        "        prediction_vector = self.fc2(intermediate_vector).squeeze()\n",
        "\n",
        "        if apply_sigmoid:\n",
        "            prediction_vector = F.sigmoid(prediction_vector)\n",
        "        return prediction_vector\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the CNN on the domain specific word2vec model"
      ],
      "metadata": {
        "id": "HOGmY-8xaLCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to explore the effectiveness of the three vectorization methods employed in this assignment, the cnn model will be trained using each of them when deriving the embeddings while using the short description column to train a baseline model."
      ],
      "metadata": {
        "id": "ET0C5Aa6aXQN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Baseline model trained on the short descriptions"
      ],
      "metadata": {
        "id": "zNur1lKjaq8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare embeddings for training loop and initialize the classifier\n",
        "dataset_short_desc = Dataset.load_df_and_make_vectorizer(df)\n",
        "dataloader_short_desc = DataLoader(dataset=dataset_short_desc, batch_size=cnn_args.batch_size,\n",
        "                            shuffle=True, drop_last=True)\n",
        "\n",
        "vectorizer_short_desc = dataset_short_desc.get_vectorizer()\n",
        "words = vectorizer_short_desc.description_vocab._token_to_idx.keys()\n",
        "word_to_idx = {word: idx for idx, word in enumerate(word2vec_model.index2word)}\n",
        "embeddings = make_embedding_matrix(word2vec_model.vectors, word_to_idx, words = words)\n",
        "\n",
        "cnn_classifier_short_word2vec = CNNClassifier(embedding_size=embeddings.shape[1], \n",
        "                            num_embeddings=len(vectorizer_short_desc.description_vocab),\n",
        "                            num_channels=cnn_args.num_channels,\n",
        "                            hidden_dim=cnn_args.hidden_dim,  \n",
        "                            dropout_p=cnn_args.dropout_p,\n",
        "                            pretrained_embeddings=embeddings,\n",
        "                            padding_idx=0)\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# train the model \n",
        "cnn_classifier_short_word2vec, train_state = train_model(cnn_classifier_short_word2vec, dataset_short_desc, loss_func)\n",
        "cnn_classifier_short_word2vec"
      ],
      "metadata": {
        "id": "aSfPzaCyqk8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Full description model with word2vec embeddings"
      ],
      "metadata": {
        "id": "booGBVZbeMcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare embeddings for training loop and initialize the classifier\n",
        "dataset_long_desc = Dataset.load_df_and_make_vectorizer(df, short=False)\n",
        "dataloader_long_desc = DataLoader(dataset=dataset_long_desc, batch_size=cnn_args.batch_size,\n",
        "                            shuffle=True, drop_last=True)\n",
        "\n",
        "vectorizer_long_desc = dataset_long_desc.get_vectorizer()\n",
        "words = vectorizer_long_desc.description_vocab._token_to_idx.keys()\n",
        "word_to_idx = {word: idx for idx, word in enumerate(word2vec_model.index2word)}\n",
        "embeddings = make_embedding_matrix(word2vec_model.vectors, word_to_idx, words = words)\n",
        "\n",
        "cnn_classifier_long_word2vec = CNNClassifier(embedding_size=embeddings.shape[1], \n",
        "                            num_embeddings=len(vectorizer_long_desc.description_vocab),\n",
        "                            num_channels=cnn_args.num_channels,\n",
        "                            hidden_dim=cnn_args.hidden_dim,  \n",
        "                            dropout_p=cnn_args.dropout_p,\n",
        "                            pretrained_embeddings=embeddings,\n",
        "                            padding_idx=0)\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# train the model \n",
        "cnn_classifier_long_word2vec, train_state = train_model(cnn_classifier_long_word2vec, dataset_long_desc, loss_func)\n",
        "cnn_classifier_long_word2vec"
      ],
      "metadata": {
        "id": "MjvwpN-BazWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the CNN classifier using GLOVE embeddings"
      ],
      "metadata": {
        "id": "QyK02_ipcmUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Baseline model with glove embeddings"
      ],
      "metadata": {
        "id": "kgbmmnUWcwZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare embeddings for training loop and initialize the classifier\n",
        "words = vectorizer_short_desc.description_vocab._token_to_idx.keys()\n",
        "word_to_idx = {word: idx for idx, word in enumerate(glove_model.index2word)}\n",
        "embeddings = make_embedding_matrix(glove_model.vectors, word_to_idx, words = words)\n",
        "\n",
        "cnn_classifier_short_glove = CNNClassifier(embedding_size=embeddings.shape[1], \n",
        "                            num_embeddings=len(vectorizer_short_desc.description_vocab),\n",
        "                            num_channels=cnn_args.num_channels,\n",
        "                            hidden_dim=cnn_args.hidden_dim,  \n",
        "                            dropout_p=cnn_args.dropout_p,\n",
        "                            pretrained_embeddings=embeddings,\n",
        "                            padding_idx=0)\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# train the model \n",
        "cnn_classifier_short_glove, train_state = train_model(cnn_classifier_short_glove, dataset_short_desc, loss_func)\n",
        "cnn_classifier_short_glove"
      ],
      "metadata": {
        "id": "6LRBLqheci0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Full description model with glove embeddings"
      ],
      "metadata": {
        "id": "Txl0wnlpdy3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare embeddings for training loop and initialize the classifier\n",
        "words = vectorizer_long_desc.description_vocab._token_to_idx.keys()\n",
        "word_to_idx = {word: idx for idx, word in enumerate(glove_model.index2word)}\n",
        "embeddings = make_embedding_matrix(glove_model.vectors, word_to_idx, words = words)\n",
        "\n",
        "cnn_classifier_long_glove = CNNClassifier(embedding_size=embeddings.shape[1], \n",
        "                            num_embeddings=len(vectorizer_long_desc.description_vocab),\n",
        "                            num_channels=cnn_args.num_channels,\n",
        "                            hidden_dim=cnn_args.hidden_dim,  \n",
        "                            dropout_p=cnn_args.dropout_p,\n",
        "                            pretrained_embeddings=embeddings,\n",
        "                            padding_idx=0)\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# train the model \n",
        "cnn_classifier_long_glove, train_state = train_model(cnn_classifier_long_glove, dataset_long_desc, loss_func)\n",
        "cnn_classifier_long_glove"
      ],
      "metadata": {
        "id": "A2fJJqZzduq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the cnn on one hot encoded dataset"
      ],
      "metadata": {
        "id": "mUsjcnERr5HW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Baseline one hot encoded classifier"
      ],
      "metadata": {
        "id": "TR9acuW-sB6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot = One_hot_Vectorizer.from_dataframe(df, target_cat = False)\n",
        "words = one_hot.description_vocab._token_to_idx.keys()\n",
        "embeddings = make_one_hot_matrix(one_hot, words)\n",
        "\n",
        "cnn_classifier_short_one_hot = CNNClassifier(embedding_size=len(words), \n",
        "                            num_embeddings=len(words),\n",
        "                            num_channels=cnn_args.num_channels,\n",
        "                            hidden_dim=cnn_args.hidden_dim,  \n",
        "                            dropout_p=cnn_args.dropout_p,\n",
        "                            pretrained_embeddings=embeddings,\n",
        "                            padding_idx=0)\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# train the model \n",
        "cnn_classifier_short_one_hot, train_state = train_model(cnn_classifier_short_one_hot, dataset_short_desc, loss_func)\n",
        "cnn_classifier_short_one_hot"
      ],
      "metadata": {
        "id": "QDKm7b13hI0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One hot encoding on the shortened job description"
      ],
      "metadata": {
        "id": "SRtRYUvYsHtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot = One_hot_Vectorizer.from_dataframe(df, target_cat = False)\n",
        "words = one_hot.description_vocab._token_to_idx.keys()\n",
        "embeddings = make_one_hot_matrix(one_hot, words)\n",
        "\n",
        "cnn_classifier_short_one_hot = CNNClassifier(embedding_size=len(words), \n",
        "                            num_embeddings=len(words),\n",
        "                            num_channels=cnn_args.num_channels,\n",
        "                            hidden_dim=cnn_args.hidden_dim,  \n",
        "                            dropout_p=cnn_args.dropout_p,\n",
        "                            pretrained_embeddings=embeddings,\n",
        "                            padding_idx=0)\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# train the model \n",
        "cnn_classifier_short_one_hot, train_state = train_model(cnn_classifier_short_one_hot, dataset_short_desc, loss_func)\n",
        "cnn_classifier_short_one_hot"
      ],
      "metadata": {
        "id": "1pAEGyY2sOyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One hot encoding on the full job description"
      ],
      "metadata": {
        "id": "yd7ni8ixtEU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot = One_hot_Vectorizer.from_dataframe(df, target_cat = False)\n",
        "words = one_hot.description_vocab._token_to_idx.keys()\n",
        "embeddings = make_one_hot_matrix(one_hot, words)\n",
        "\n",
        "cnn_classifier_long_one_hot = CNNClassifier(embedding_size=len(words), \n",
        "                            num_embeddings=len(words),\n",
        "                            num_channels=cnn_args.num_channels,\n",
        "                            hidden_dim=cnn_args.hidden_dim,  \n",
        "                            dropout_p=cnn_args.dropout_p,\n",
        "                            pretrained_embeddings=embeddings,\n",
        "                            padding_idx=0)\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# train the model \n",
        "cnn_classifier_long_one_hot, train_state = train_model(cnn_classifier_long_one_hot, dataset_long_desc, loss_func)\n",
        "cnn_classifier_long_one_hot"
      ],
      "metadata": {
        "id": "fxTFl2zrtLeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-tkj7Kzx24n"
      },
      "outputs": [],
      "source": [
        "#compute the loss & accuracy on the test set using the best available model\n",
        "\n",
        "cnn_classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "dataset_long_desc.class_weights = dataset_long_desc.class_weights.to(cnn_args.device)\n",
        "loss_func = nn.CrossEntropyLoss(dataset_long_desc.class_weights)\n",
        "\n",
        "dataset_long_desc.set_split('test')\n",
        "batch_generator = generate_batches(dataset_long_desc, \n",
        "                                   batch_size=cnn_args.batch_size, \n",
        "                                   device=cnn_args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # compute the output\n",
        "    y_pred =  classifier(batch_dict['x_data'])\n",
        "    \n",
        "    # compute the loss\n",
        "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "    # compute the accuracy\n",
        "    acc_t = compute_accuracy_binary(y_pred.float(), batch_dict['y_target'].float())\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc\n",
        "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
        "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.10 (conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c89f1b53f5cd444e3157448a8cfaf5cd042e20f991203c5786aa4f19ac50ffc0"
      }
    },
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "booGBVZbeMcE",
        "kgbmmnUWcwZq"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7e31080dc04f488f8fa1750c31b91af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39f7fc65e6684bd5bf6e9adfbea1d190",
              "IPY_MODEL_8219048cd699438e9dfd4bfbac686f53",
              "IPY_MODEL_b9b794275bd44885ae7195ed6fc3d324"
            ],
            "layout": "IPY_MODEL_ba100c1b5288414a80b85360c3924b0b"
          }
        },
        "39f7fc65e6684bd5bf6e9adfbea1d190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b4d4c15c6314dbc8da6afc07f748644",
            "placeholder": "​",
            "style": "IPY_MODEL_0b9160755ad141d5b8df66dbcfe1b744",
            "value": " 41%"
          }
        },
        "8219048cd699438e9dfd4bfbac686f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bea1e2e32f842e883de3f6c472fceae",
            "max": 29655,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3125f975af66486f9ab98a066349c814",
            "value": 12046
          }
        },
        "b9b794275bd44885ae7195ed6fc3d324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8059e313aeb24bd18efb649d97abe6d3",
            "placeholder": "​",
            "style": "IPY_MODEL_417f67bac06148ba8b50d28681c7cf6f",
            "value": " 12046/29655 [01:20&lt;01:57, 150.41it/s]"
          }
        },
        "ba100c1b5288414a80b85360c3924b0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b4d4c15c6314dbc8da6afc07f748644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b9160755ad141d5b8df66dbcfe1b744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bea1e2e32f842e883de3f6c472fceae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3125f975af66486f9ab98a066349c814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8059e313aeb24bd18efb649d97abe6d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "417f67bac06148ba8b50d28681c7cf6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}